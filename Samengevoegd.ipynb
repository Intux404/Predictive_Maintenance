{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Maintenance\n",
    "\n",
    "## Inleiding\n",
    "\n",
    "**Auteurs:** R. Coenen, Y. Dera, M. Vliex & S. van Wesel <br>\n",
    "## Inhoudsopgave\n",
    "\n",
    "* [1. Data selectie](#DataSelectie)\n",
    "* [1.1. Achtergrond informatie](#AchtergrondInfo)\n",
    "* [1.2. Theoretisch kader](#TheoretischKader)\n",
    "* [1.3. Doel](#Doel)\n",
    "* [2. Data preparatie](#DataPreparatie)\n",
    "* [2.1. Data profiling](#DataProfiling)\n",
    "* [2.2. Data Cleaning](#DataCleaning)\n",
    "* [2.3. Data Wrangling](#DataWrangling)\n",
    "* [3. Uitwerkingen en algoritmen](#Uitwerkingen)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data selectie <a class=\"anchor\" id=\"DataSelectie\"></a><br>\n",
    "\n",
    "(Sander en Maurice) <br>\n",
    "\n",
    "Vanuit de opdrachtgever is vraag gekomen aan de slag te gaan met machine learning op het gebied van predictive maintenance. Hierbij heeft de opdrachtgever de projectgroep in staat gesteld op zoek te gaan naar een dataset die betrekking heeft op het voorspellen van onderhoud van machines. De aard van deze machines is vrij om te kiezen, ook zal de projectgroep zich gaan verdiepen in specifieke machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Achtergrond informatie <a class=\"anchor\" id=\"AchtergrondInfo\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Sander en Maurice)<br>\n",
    "\n",
    "De dataset die gehanteerd wordt voor het onderzoek is gevonden via [Kaggle](https://www.kaggle.com/) met de naam \"Microsoft Azure Predictive Maintenance\". De dataset is te raadplegen via de [*Website van Kaggle*](https://www.kaggle.com/arnabbiswas1/microsoft-azure-predictive-maintenance) {1}. De dataset is een verzameling van een totaal van 5 bestanden met een totaal van 18 kolommen die overlap met elkaar kennen. Hiermee wordt bedoelt dat in sommige kollomen dezelfde kolomnamen terugkomen (een voorbeeld hiervan is het machineID). Hiernaast is de bron oorspronkelijk afkomstig van [Azure AI Notebooks for predictive Maintenance](https://docs.microsoft.com/nl-nl/azure/architecture/data-science-process/predictive-maintenance-playbook#training-resources-for-predictive-maintenance) {2}, maar aangezien de downloadlink niet meer op de site van Azure te vinden is, is deze beschikbaar gesteld op Kaggle. Op basis van de 18 kolommen is het mogelijk onderhoud van machines te voorspellen, wat deze kolommen betekenen is terug te vinden in [paragraaf 2.1.2.](#TyperenData).\n",
    "\n",
    "(Rob & Youri)<br>\n",
    "\n",
    "Aan de projectgroep is de opdracht verstrekt om op zoek te gaan naar een dataset die betrekking heeft op de monitoring van apparatuur/machines in combinatie met sensoren. Op basis van deze sensor informatie zou o.a. een predictie gemaakt kunnen worden over de resterende levensduur van een apparaat en/of component evenals wanneer onderhoud wenselijk is. \n",
    "\n",
    "De doelstelling is, om op basis van een (preprocessed) dataset een onderzoek uit te voeren en een pipeline te realiseren die aan de slag gaat met deze (ruwe) data en dit omzet naar een predictie model. Dit binnen een Jupyter Notebook en in combinatie met Python scripts.\n",
    "\n",
    "In een introductie gesprek zijn de volgende 3 typeringen van onderhoud aan bod gekomen:\n",
    "\n",
    "<b>Reactive (reactief)</b> - Onderhoud uitvoeren zodra er een probleem is<br>\n",
    "Probleem: onverwachte storingen kunnen duur (kosten) en potentieel gevaarlijk zijn\n",
    "\n",
    "<b>Scheuduled (gepland)</b> - Onderhoud uitvoeren op basis van een (regelmatig) schema<br>\n",
    "Probleem: onnodig onderhoud kan verspilling zijn; mogelijk worden niet alle storingen verholpen\n",
    "\n",
    "<b>Predictive (voorspellend)</b> - Voorspellen wanneer zich problemen zullen voordoen<br>\n",
    "Probleem: moeilijk om nauwkeurige voorspellingen te doen voor complexe apparatuur\n",
    "\n",
    "Kortweg gezegd is het doel om kosten te verminden door te voorspellen wanneer onderhoud nodig is. \n",
    "\n",
    "De projectgroep is aan de slag gegaan met het zoeken naar datasets en eenieder heeft verschillende datasets ingebracht om mee aan te slag te gaan. Vervolgens is de keuze gemaakt voor één dataset, de Microsoft Azure Predictive Maintenance dataset, zoals beschikbaar gesteld op <a href=\"https://www.kaggle.com/arnabbiswas1/microsoft-azure-predictive-maintenance\" title=\"Azure dataset\">Kaggle</a>. \n",
    "\n",
    "Deze (voorbeeld) data is afkomstig van het Microsoft project \"Azure AI Notebooks for Predictive Maintenance\" (welke per 15 oktober 2020 beëndigd is). De data is echter nog altijd toegankelijk om te gebruiken.\n",
    "\n",
    "Deze dataset kan volgens Microsoft gebruikt worden om aan te slag te gaan met machine learning models gerelateerd aan predictive maintenance, ofwel het voorspellen van onderhoud.\n",
    "\n",
    "De dataset bestaat uit een vijftal CSV (door komma gescheiden) bestanden, namelijk errors, fouten, machines, onderhoud en telemetrie en beslaat bijna een miljoen rijen.\n",
    "\n",
    "Iets dieper uitgediept zien de datasets er als volgt uit:\n",
    "\n",
    "• <b>Machinecondities en -gebruik</b>: Geeft de omstandigheden van de machine in gebruik weer, bijvoorbeeld door sensoren verzamelde gegevens;<br>\n",
    "• <b>Faal geschiedenis</b>: De storingshistorie van een machine of een component binnen de machine;<br>\n",
    "• <b>Onderhoudshistorie</b>: De reparatiegeschiedenis van een machine, bijvoorbeeld foutcodes, eerdere onderhoudsactiviteiten of vervanging van componenten.<br>\n",
    "• <b>Machine eigenschapen</b>: De kenmerken van een machine, bijv. CPU, merk en model, locatie.\n",
    "\n",
    "Op detailniveau bestaan de CSV bestanden uit de volgende gegevens:<br><br>\n",
    "• <b>Telemetrie tijd data</b>: Bevat data, op uur niveau, over de rotatie, druk en trillingen; verzameld over 10 machines (in het jaar 2015);<br>\n",
    "• <b>Error</b>: Dit zijn fouten die de machines ondervinden wanneer ze in werking/actief zijn. Aangezien deze fouten de machines niet uitschakelen, worden zij niet als verstoringen beschouwd. (De foutdatum en -tijd worden afgerond op het dichtstbijzijnde uur, aangezien de telemetriegegevens om het uur worden verzameld);<br>\n",
    "• <b>Onderhoud</b>: Wanneer een onderdeel van een machine wordt vervangen, wordt dat als een record in deze tabel vastgelegd. Componenten worden in twee situaties vervangen:<br><br> \n",
    "-> 1. Tijdens het reguliere geplande bezoek vervangt de technicus het onderdeel (proactief onderhoud);<br><br>\n",
    "-> 2. Een onderdeel gaat kapot en de technicus voert een ongepland onderhoud uit om het onderdeel te vervangen (reactief onderhoud). (Dit wordt beschouwd als een storing en de overeenkomstige gegevens worden vastgelegd onder verstoringen. De onderhoudsgegevens hebben zowel betrekking op 2014 als op 2015. Deze gegevens worden afgerond op het dichtstbijzijnde uur, aangezien de telemetriegegevens om het uur worden verzameld).<br><br>\n",
    "• <b>Verstoringen</b>: Elk record staat voor de vervanging van een onderdeel als gevolg van een defect. Deze gegevens zijn een deelverzameling van de onderhoudsgegevens. (Deze gegevens worden afgerond op het dichtstbijzijnde uur, aangezien de telemetriegegevens om het uur worden verzameld)<br>\n",
    "• <b>Metadata</b>: Model type en leeftijd van de machines\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Theoretisch kader <a class=\"anchor\" id=\"TheoretischKader\"></a><br>\n",
    "\n",
    "> Inhoud\n",
    "> + [Introductie](#TKIntroductie)\n",
    "> + [Predictive Maintenance](#TKPredictiveMaint)\n",
    "\n",
    "### Introductie <a class=\"anchor\" id=\"TKIntroductie\"></a>\n",
    "\n",
    "### 1.2.1. Predictive maintenance <a class=\"anchor\" id=\"TKPredictiveMaint\"></a>\n",
    "Predictive maintenance is een techniek dat gebruik maakt van data analyse tools en technieken om afwijkingen in een organisatie en mogelijke gebreken in apparatuur en processen vroegtijdig te detecteren zodat deze afgehandeld kunnen worden nog vóór dat deze resulteren in een fout. [FiixSoftware.com](https://www.fiixsoftware.com/maintenance-strategies/predictive-maintenance/) {3}. Enerzijds focust predictive maintenance zich op het voorkomen van [reactive maintenance]([#TKReactiveMaint](https://www.fiixsoftware.com/maintenance-strategies/reactive-maintenance/)), waarbij het anderzijds de kosten voor [preventive maintenance]([#TKPreventiveMaint](https://www.fiixsoftware.com/maintenance-strategies/preventative-maintenance/)) probeert te verlagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Doel <a class=\"anchor\" id=\"Doel\"></a><br>\n",
    "Het doel van het project betreft het inzichtelijk maken van de mogelijkheden van het gebruik van machine learning binnen predictive maintenance richting de opdrachtgever. Hierbij zal de projectgroep zich verdiepen in een open dataset (waarover de opdrachtgever geen kennis noch eigendom heeft), gericht op predictive maintenance. Dit betekent dat vanuit het perspectief van data gezocht wordt naar inzichten en er geen specifiek probleem aanwezig is. Hiermee wordt het project gekenmerkt met een data driven benadering.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data preparatie <a class=\"anchor\" id=\"DataPreparatie\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voordat er aan de slag gegaan kan worden met de data(set) dienen er een aantal stappen/iteraties over de data uitgevoerd te worden, te weten: verzamelen (1), typeren(2), opschonen (3) en voorbewerken (4).\n",
    "\n",
    "Het volgende hoofdstuk behandeld deze viertal fases en beschrijft de activiteiten die plaats hebben gevonden binnen deze fases.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Data profiling (stap 1: verzamelen)<a class=\"anchor\" id=\"DataProfiling\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allereerst even de betekenis van data profiling. Data profiling is het proces van het onderzoeken van de beschikbaar gestelde gegevens uit een bestaande informatiebron, in het geval van dit project, de Microsoft Azure dataset en bijbehorende literatuur. Door het toepassen van gegevensprofilering wordt er inzicht verkregen in de structuur en inhoud van de data/gegevens, evenals de onderlinge verbanden en (afhankelijk van de grootte) welke gegevens relevant zijn om te gebruiken.\n",
    "\n",
    "Uitgediept bestaat het profileren van de gegevens uit de volgende zaken: <br>\n",
    "• Problemen inzake de datakwaliteit aan het licht brengen (welke in een later stadium gecorrigeerd wordt, indien mogelijk);<br>\n",
    "• Het beschrijven van de metrieken (voorbeelden zijn minimaal, maximaal, aantal, som etc.);<br>\n",
    "• Het beschrijven van gegevenstypen (string, integer, float etc.) en diens lengte;<br>\n",
    "• Het taggen/classificeren van gegevens met trefwoorden, beschrijvingen en/of categorieën;<br>\n",
    "• Eventuele metadata ontdekken (en beoordelen of deze van goede kwaliteit is en toepasbaar is binnen het project)\n",
    "\n",
    "<b>Soorten gegevensprofilering</b><br>\n",
    "Er zijn een drietal hoofdtypes inzake gegevensprofilering:\n",
    "\n",
    "<i>#1 - Ontdekken van structuur</i><br>\n",
    "Controleren of gegevens consistent zijn en correct zijn geformatteerd, en Structure discovery helpt te begrijpen hoe goed gegevens zijn gestructureerd.\n",
    "\n",
    "<i>#2 - Opsporen van inhoud</i><br>\n",
    "Op zoek gaan naar individuele gegevensrecords om fouten te ontdekken. Bij inhoudelijke ontdekking wordt nagegaan welke specifieke rijen in een tabel problemen bevatten en welke systematische problemen zich in de gegevens voordoen.\n",
    "\n",
    "<i>#3 - Ontdekken van relaties</i><br>\n",
    "Ontdekken hoe delen van de gegevens met elkaar samenhangen. Bijvoorbeeld sleutelrelaties tussen databasetabellen, verwijzingen tussen cellen of tabellen in een spreadsheet. Inzicht in relaties is van cruciaal belang voor het hergebruik van gegevens; gerelateerde gegevensbronnen moeten worden samengevoegd tot één gegevensbron of geïmporteerd op een manier waarbij belangrijke relaties behouden blijven.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data Profiling in dit project</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1. Inladen van de data <a class=\"anchor\" id=\"InladenData\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om aan de slag te kunnen gaan met de data, dient deze eerst ingeladen te worden. Deze dataset, afkomstig van Kaggle, bevat een cijftal .CSV (kommagescheiden) bestanden, die in zijn totaliteit uit 18 kolommen en 876.100 rijen bestaat. Het inladen van de data kan gebeuren aan de hand van de Pandas module binnen Python. We voeren hiervoor de volgende code uit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19984/4080736814.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierdoor wordt de Pandas module geïmporteerd en hernoemd naar 'pd' zodat de module met deze afkorting aangeroepen kan worden i.p.v. het voluit schrijven van de modulenaam. Nu voeren we de volgende reges code in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTelemetry = pd.read_csv ('Data\\PdM_telemetry.csv')\n",
    "dfErrors = pd.read_csv ('Data\\PdM_errors.csv')\n",
    "dfFailures = pd.read_csv ('Data\\PdM_failures.csv')\n",
    "dfMachines = pd.read_csv ('Data\\PdM_machines.csv')\n",
    "dfMaint = pd.read_csv ('Data\\PdM_maint.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deze regels code zorgen ervoor dat de juiste CSV (kommagescheiden bestanden) ingeladen worden.\n",
    "Deze code zorgt er voor dat er een \"data frame object\" terug gegeven wordt; dit kan gezien worden als een soort van Excel bestand.\n",
    "De df(naam) code (bijv. 'dfTelemetry') zorgt ervoor dat deze dataframes snel opgeroepen kunnen worden. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Met onderstaande code kan er een voorbeeld van het data frame getoond worden inclusief een vertoning van de rijen en kolommen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>machineID</th>\n",
       "      <th>volt</th>\n",
       "      <th>rotate</th>\n",
       "      <th>pressure</th>\n",
       "      <th>vibration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>176.217853</td>\n",
       "      <td>418.504078</td>\n",
       "      <td>113.077935</td>\n",
       "      <td>45.087686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01 07:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>162.879223</td>\n",
       "      <td>402.747490</td>\n",
       "      <td>95.460525</td>\n",
       "      <td>43.413973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01 08:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>170.989902</td>\n",
       "      <td>527.349825</td>\n",
       "      <td>75.237905</td>\n",
       "      <td>34.178847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01 09:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>162.462833</td>\n",
       "      <td>346.149335</td>\n",
       "      <td>109.248561</td>\n",
       "      <td>41.122144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01 10:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>157.610021</td>\n",
       "      <td>435.376873</td>\n",
       "      <td>111.886648</td>\n",
       "      <td>25.990511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876095</th>\n",
       "      <td>2016-01-01 02:00:00</td>\n",
       "      <td>100</td>\n",
       "      <td>179.438162</td>\n",
       "      <td>395.222827</td>\n",
       "      <td>102.290715</td>\n",
       "      <td>50.771941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876096</th>\n",
       "      <td>2016-01-01 03:00:00</td>\n",
       "      <td>100</td>\n",
       "      <td>189.617555</td>\n",
       "      <td>446.207972</td>\n",
       "      <td>98.180607</td>\n",
       "      <td>35.123072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876097</th>\n",
       "      <td>2016-01-01 04:00:00</td>\n",
       "      <td>100</td>\n",
       "      <td>192.483414</td>\n",
       "      <td>447.816524</td>\n",
       "      <td>94.132837</td>\n",
       "      <td>48.314561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876098</th>\n",
       "      <td>2016-01-01 05:00:00</td>\n",
       "      <td>100</td>\n",
       "      <td>165.475310</td>\n",
       "      <td>413.771670</td>\n",
       "      <td>104.081073</td>\n",
       "      <td>44.835259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876099</th>\n",
       "      <td>2016-01-01 06:00:00</td>\n",
       "      <td>100</td>\n",
       "      <td>171.336037</td>\n",
       "      <td>496.096870</td>\n",
       "      <td>79.095538</td>\n",
       "      <td>37.845245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>876100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   datetime  machineID        volt      rotate    pressure  \\\n",
       "0       2015-01-01 06:00:00          1  176.217853  418.504078  113.077935   \n",
       "1       2015-01-01 07:00:00          1  162.879223  402.747490   95.460525   \n",
       "2       2015-01-01 08:00:00          1  170.989902  527.349825   75.237905   \n",
       "3       2015-01-01 09:00:00          1  162.462833  346.149335  109.248561   \n",
       "4       2015-01-01 10:00:00          1  157.610021  435.376873  111.886648   \n",
       "...                     ...        ...         ...         ...         ...   \n",
       "876095  2016-01-01 02:00:00        100  179.438162  395.222827  102.290715   \n",
       "876096  2016-01-01 03:00:00        100  189.617555  446.207972   98.180607   \n",
       "876097  2016-01-01 04:00:00        100  192.483414  447.816524   94.132837   \n",
       "876098  2016-01-01 05:00:00        100  165.475310  413.771670  104.081073   \n",
       "876099  2016-01-01 06:00:00        100  171.336037  496.096870   79.095538   \n",
       "\n",
       "        vibration  \n",
       "0       45.087686  \n",
       "1       43.413973  \n",
       "2       34.178847  \n",
       "3       41.122144  \n",
       "4       25.990511  \n",
       "...           ...  \n",
       "876095  50.771941  \n",
       "876096  35.123072  \n",
       "876097  48.314561  \n",
       "876098  44.835259  \n",
       "876099  37.845245  \n",
       "\n",
       "[876100 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTelemetry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2. Typeren van de data <a class=\"anchor\" id=\"TyperenData\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Format</b><br>\n",
    "Deze dataset bevat gestructureerde gegevens. Iedere atribuut valt onder een categorie. De dataset zelf bevat, op moment van verkrijgen, nog uit een vijftal losse CSV bestanden. Deze staan los van elkaar en dienen nog, middels relaties, gekoppeld te worden eaan elkaar. Zie voor meer informatie hoofdstuk 2.3 'Data Wrangling'.\n",
    "\n",
    "<b>Structuur</b><br>\n",
    "Het data format betreft dus een CSV bestand. Een CSV-bestand (door komma’s gescheiden waarden) is een bestandstype, In CSV-bestanden wordt informatie niet in kolommen opgeslagen, maar wordt deze gescheiden door komma’s. \n",
    "\n",
    "<b>Context</b><br>\n",
    "De volgende kolommen zijn terug te vinden in de datasets:\n",
    "<img src=\"Images/Datamodel.jpg\" alt=\"Datamodel\" width='650'/>\n",
    "\n",
    "| Feature   | Omschrijving | Voorbeeld data    | Data Type | Type variabele | Meeteenheid | (Oorspronkelijke) databron |\n",
    "| ----------| -------------| ----------------- | ----------| ---------------| ------------|  --------------------------|\n",
    "| machineID | Iedere machine wordt gekenmerkt door een uniek identificatienummer | 1 | Int64 | Kwalitatief (discreet) | n.v.t | PdM_machines.csv |\n",
    "| model     | Er zijn verschillende soorten modellen, die gekenmerkt worden door een modelnummer | model 3 | text | Kwalitatief (discreet) | n.v.t |PdM_machines.csv |\n",
    "| age       | De leeftijd van de machines/compontenten | 18 | Int64 | Kwantitatief (discreet) | Maanden | PdM_machines.csv |\n",
    "| datetime  | Geeft de datum en tijd weer | 3-1-2015 07:00:00 | datetime | Kwantitatief (continue) | Uren, minuten, seconde | PdM_errors.csv     |\n",
    "| errorID   | Iedere error wordt gekenmerkt door een (uniek) error nummer | error1 | text | Kwalitatief (discreet) | n.v.t | PdM_errors.csv     |\n",
    "| failure   | Geeft aan welk component gefaald is | comp4 | text | Kwalitatief (discreet) | n.v.t | PdM_failures.csv |\n",
    "| comp      | Ieder component wordt gekenmerkt door een componentnummer | comp2 | text | Kwalitatief (discreet) | n.v.t | PdM_maint.csv |\n",
    "| volt      | De elektrische spanning in volt | 176217853015625 | Int64 | Kwantitatief (continue)| n.v.t | PdM_maint.csv |\n",
    "| rotate    | < Nog invullen > | 418504078221616   | Int64 | Kwantitatief (continue) | n.v.t | PdM_maint.csv  |\n",
    "| pressure  | < Nog invullen > | 113077935462083   | Int64 | Kwantitatief (continue) | n.v.t | PdM_maint.csv  |\n",
    "| vibration | Periodieke beweging van een voorwerp of medium | 450876857639276 | Int64 | Kwantitatief (continue) | n.v.t | PdM_maint.csv |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Data cleaning <a class=\"anchor\" id=\"DataCleaning\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Data Wrangling <a class=\"anchor\" id=\"DataWrangling\"></a>\n",
    "Data wrangling betreft het op elkaar laten passen van de data. Tot nu toe betreffen het 5 losse datasets die allen op elkaar dienen te passen. Dat zal in deze paragraaf aan bod komen.  \n",
    "\n",
    "De eerste stap van het op elkaar laten passen is het inzichtelijk maken van het datamodel. Middels gebruik te maken van [Microsoft PowerBI](https://powerbi.microsoft.com/nl-nl/) wordt een model opgesteld waarbij de relaties tussen de tabellen geïdentificeerd kunnen worden. Dit heeft als resultaat het onderstaat Entity Attribute Relation Diagram (EARD):\n",
    "\n",
    "<img src=\"img/Oorspronkelijk_dataModel.png\" alt=\"oorspronkelijk datamodel\" width=\"650\"/><br>\n",
    "*Oorspronkelijk datamodel*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas lib for dataframe operations\n",
    "import pandas as pd\n",
    "#numpy lib for two-dimensional arrays\n",
    "import numpy as np\n",
    "#scikit learn lib for visualising data\n",
    "import sklearn as sk\n",
    "#matplot lib for visualising data\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "#seaborn lib for visualising more fancy which is based on the matplot lib\n",
    "import seaborn as sb\n",
    "import math as math\n",
    "\n",
    "# Loading all data files\n",
    "dfTelemetry = pd.read_csv ('data\\PdM_telemetry.csv')\n",
    "dfErrors = pd.read_csv ('data\\PdM_errors.csv')\n",
    "dfFailures = pd.read_csv ('data\\PdM_failures.csv')\n",
    "dfMachines = pd.read_csv ('data\\PdM_machines.csv')\n",
    "dfMaint = pd.read_csv ('data\\PdM_maint.csv')\n",
    "\n",
    "#Merging the tables into the dataframe\n",
    "\n",
    "# #Left join failures on maintenance to create df1\n",
    "df1 = pd.merge(dfMaint, dfFailures, how='left', left_on=['datetime', 'machineID', 'comp'], right_on = ['datetime', 'machineID', 'failure'])\n",
    "df1['failure'] = df1['failure'].fillna(0) #indicates maint was not a failure\n",
    "df1.loc[((df1.failure == 'comp1') | (df1.failure == 'comp2') | (df1.failure == 'comp3') | (df1.failure == 'comp4')), 'failure'] = '1' #indicates maintenance was a failure\n",
    "# df1.to_csv('data/df1output.csv') #test output to validate\n",
    "\n",
    "# #Right join machines on df1 to create df2\n",
    "df2 = pd.merge(dfMachines, df1, how='right', left_on=['machineID'], right_on=['machineID'])\n",
    "df2\n",
    "\n",
    "#Concatenation of datasets\n",
    "# https://www.youtube.com/watch?v=iYWKfUOtGaw&ab_channel=DataSchool\n",
    "# df = pd.concat((dfTelemetry, dfMachines, dfErrors, dfFailures, dfMaint))\n",
    "# print (df.head(1000))\n",
    "# print (dfTelemetry.head(1000))\n",
    "# print (dfTelemetry.machineID.nunique())\n",
    "# print (dfErrors.machineID.nunique())\n",
    "# print (dfFailures.machineID.nunique())\n",
    "# print (dfMachines.machineID.nunique())\n",
    "# print (dfMaint.machineID.nunique())\n",
    "# print (df.shape)\n",
    "\n",
    "# print (df.info()) #Print info about (non)null-counts\n",
    "\n",
    "#Merging datasets\n",
    "#inner Join\n",
    "# df1 = pd.merge(dfTelemetry, dfMaint, how='inner')\n",
    "# print (df1.head())\n",
    "\n",
    "# #outer join\n",
    "# df2 = pd.merge(dfTelemetry, dfMaint, how='outer')\n",
    "# print (df2.head())\n",
    "\n",
    "# #left join -> considered from the table which will be joined on\n",
    "# df3 = pd.merge(dfTelemetry, dfMaint, how='left')\n",
    "# print (df3.head())\n",
    "\n",
    "# #right join -> considerd from the table which will be joined\n",
    "# df4 = pd.merge(dfTelemetry, dfMaint, how='right')\n",
    "# print (df4.head())\n",
    "# # df2.columns\n",
    "\n",
    "#merging with other column names (selecting specific PK's)\n",
    "# df3 = pd.merge(dfTelemetry, dfMachines, left_on='machineID', right_on='machineID')\n",
    "# print (df3.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Uitwerkingen en algoritmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime      object\n",
       "machineID      int64\n",
       "volt         float64\n",
       "rotate       float64\n",
       "pressure     float64\n",
       "vibration    float64\n",
       "errorID       object\n",
       "failure       object\n",
       "model         object\n",
       "age          float64\n",
       "comp          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTelemetry = pd.read_csv ('data\\PdM_telemetry.csv')\n",
    "dfErrors = pd.read_csv ('data\\PdM_errors.csv')\n",
    "dfFailures = pd.read_csv ('data\\PdM_failures.csv')\n",
    "dfMachines = pd.read_csv ('data\\PdM_machines.csv')\n",
    "dfMaint = pd.read_csv ('data\\PdM_maint.csv')\n",
    "print (dfTelemetry.columns)\n",
    "print (dfErrors.columns)\n",
    "print (dfFailures.columns)\n",
    "print (dfMachines.columns)\n",
    "print (dfMaint.columns)\n",
    "\n",
    "# print (dfTelemetry.dtypes)\n",
    "# dfErrors.errorID.to_string()\n",
    "# print (dfErrors.errorID.dtypes)\n",
    "# print (dfFailures.dtypes)\n",
    "# print (dfMachines.dtypes)\n",
    "# print (dfMaint.dtypes)\n",
    "\n",
    "# df = pd.concat((dfTelemetry, dfErrors, dfFailures, dfMachines, dfMaint))\n",
    "# df.head(800)\n",
    "# df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliografie\n",
    "+ [Microsoft Predictive Maintenance](https://www.kaggle.com/arnabbiswas1/microsoft-azure-predictive-maintenance) {1}\n",
    "+ [What is predictive maintenance?](https://www.fiixsoftware.com/maintenance-strategies/predictive-maintenance/) {2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Later verwijderen) Trial-and-error Rob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De gemiddelde voltages, rotaties, druk en vibraties, gesorteerd per machine en gesorteerd op dag nummer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfTelemetry' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24944/3893207830.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## Pandas reeds geimporteerd en dfTelemetry reeks aangemaakt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0moefening\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdfTelemetry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'machineID'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdfTelemetry\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'day_no'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'volt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rotate'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'pressure'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'vibration'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0moefening\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dfTelemetry' is not defined"
     ]
    }
   ],
   "source": [
    "## Pandas reeds geimporteerd en dfTelemetry reeks aangemaakt\n",
    "    \n",
    "oefening = dfTelemetry.groupby(['machineID', dfTelemetry['day_no']])['volt', 'rotate', 'pressure', 'vibration'].mean()\n",
    "oefening "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "df91481e84a2b848202e6e50f0fbb9aa107aded72c389e66e2482a76ade2318d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
