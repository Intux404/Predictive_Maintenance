{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Het importeren van de benodigde bilbiotheken\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import seaborn as sb\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Het inlezen van de bestanden\n",
    "dfTelemetry = pd.read_csv('data/PdM_telemetry.csv')\n",
    "dfErrors = pd.read_csv('data/PdM_errors.csv')\n",
    "dfMaint = pd.read_csv('data/PdM_maint.csv')\n",
    "dfFailures = pd.read_csv('data/PdM_failures.csv')\n",
    "dfMachines = pd.read_csv('data/PdM_machines.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Left join failures on maintenance to create df1\n",
    "df1 = pd.merge(dfMaint, dfFailures, how='left', left_on=['datetime', 'machineID', 'comp'], right_on = ['datetime', 'machineID', 'failure'])\n",
    "df1['failure'] = df1['failure'].fillna(0) #indicates maint was not a failure\n",
    "df1.loc[((df1.failure == 'comp1') | (df1.failure == 'comp2') | (df1.failure == 'comp3') | (df1.failure == 'comp4')), 'failure'] = '1' #indicates maintenance was a failure\n",
    "df1['failure'] = df1['failure'].astype(int)\n",
    "\n",
    "#Clean error table to create df2, df2 = cleansed dfErrors tbl. \n",
    "df2 = dfErrors\n",
    "df2['Error1'] = 0\n",
    "df2['Error2'] = 0\n",
    "df2['Error3'] = 0\n",
    "df2['Error4'] = 0\n",
    "df2['Error5'] = 0\n",
    "\n",
    "df2.loc[(df2['errorID'] == 'error1'), 'Error1'] = 1\n",
    "df2.loc[(df2['errorID'] == 'error2'), 'Error2'] = 1\n",
    "df2.loc[(df2['errorID'] == 'error3'), 'Error3'] = 1\n",
    "df2.loc[(df2['errorID'] == 'error4'), 'Error4'] = 1\n",
    "df2.loc[(df2['errorID'] == 'error5'), 'Error5'] = 1\n",
    "\n",
    "# # df2 = df2.groupby(['machineID', 'datetime']).sum() #Groups on all cols.\n",
    "df2 = df2.groupby(['datetime', 'machineID'])[[f'Error{n}' for n in range (1,6)]].sum() #Groups errorID cols only\n",
    "\n",
    "##Create df3 by joining dfTelemetry on df2\n",
    "df3 = pd.merge(dfTelemetry, df2, how='left', left_on=['machineID', 'datetime'], right_on=['machineID', 'datetime'])\n",
    "\n",
    "df3['Error1'] = df3['Error1'].fillna(0)\n",
    "df3['Error2'] = df3['Error2'].fillna(0)\n",
    "df3['Error3'] = df3['Error3'].fillna(0)\n",
    "df3['Error4'] = df3['Error4'].fillna(0)\n",
    "df3['Error5'] = df3['Error5'].fillna(0)\n",
    "\n",
    "df3.Error1 = df3.Error1.astype(int)\n",
    "df3.Error2 = df3.Error2.astype(int)\n",
    "df3.Error3 = df3.Error3.astype(int)\n",
    "df3.Error4 = df3.Error4.astype(int)\n",
    "df3.Error5 = df3.Error5.astype(int)\n",
    "\n",
    "## Create df4 by joining machines on df3\n",
    "df4 = pd.merge(dfMachines, df3, how='right', left_on=['machineID'], right_on=['machineID'])\n",
    "\n",
    "## Create df5 by joining df1 on df4\n",
    "df5 = pd.merge(df1, df4, how='right', left_on=['machineID', 'datetime'], right_on=['machineID', 'datetime'])\n",
    "df = df5\n",
    "\n",
    "#Create dfSmall by inner joining df1 on df4\n",
    "dfSmall = pd.merge(df1, df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression of age and failures w/ pearson R line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failureGroupAgedf = df['failure'].groupby(df['age']).sum().reset_index()\n",
    "x = failureGroupAgedf['age']\n",
    "y = failureGroupAgedf['failure']\n",
    "\n",
    "# #polynomial\n",
    "a, b = polyfit(x, y, 1)\n",
    "\n",
    "_ = plt.plot(x, y, '.', label='data')\n",
    "_ = plt.plot(x, a + b * x, '-', label='fitted polynomial line')\n",
    "_ = plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# #Linear\n",
    "# m, b = np.linalg.lstsq(failureGroupAgedf, y)[0]\n",
    "\n",
    "# _ = plt.plot(x,y, 'o', label='original data', markersize = 10)\n",
    "# _ = plt.plot(x, m*x + b, 'r', label='fitted line')\n",
    "# _ = plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "print(scipy.stats.pearsonr(x, y))\n",
    "print(scipy.stats.spearmanr(x, y))\n",
    "print(scipy.stats.kendalltau(x, y))\n",
    "\n",
    "# print(failureGroupAgedf)\n",
    "\n",
    "# plt.figure(figsize=[15,8])\n",
    "# sb.heatmap(failureGroupAgedf.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram with classification of voltage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# volt min = 138.432075\n",
    "# volt max = 255.124717\n",
    "# bins: 130,140,150,160,170,180,190,200,210,220,230,240,250,260\n",
    "\n",
    "toCut = dfSmall.volt\n",
    "labelsUsed = [\n",
    "        '130-140',\n",
    "        '140-150',\n",
    "        '150-160',\n",
    "        '160-170',\n",
    "        '170-180',\n",
    "        '180-190',\n",
    "        '190-200',\n",
    "        '200-210',\n",
    "        '210-220',\n",
    "        '220-230',\n",
    "        '230-240',\n",
    "        '240-250',\n",
    "        '250-260'\n",
    "        ]\n",
    "\n",
    "voltcat = pd.cut(toCut,bins=[130,140,150,160,170,180,190,200,210,220,230,240,250,260],\n",
    "    labels=labelsUsed)\n",
    "dfSmall.insert(7,'voltage_class',voltcat) #Inserts the records into the new columns, but when executed again another code should be used(?)\n",
    "\n",
    "## Building the graphic\n",
    "\n",
    "# # validation code to check the amount of failures within a voltage class\n",
    "# test = dfSmall['failure'].groupby(dfSmall['voltage_class']).sum()\n",
    "# print(test)\n",
    "\n",
    "failureGroupVoltdf = dfSmall['failure'].groupby(dfSmall['voltage_class']).sum().reset_index()\n",
    "x = failureGroupVoltdf['voltage_class']\n",
    "y = failureGroupVoltdf['failure']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_figwidth(15)\n",
    "fig.set_figheight(10)\n",
    "ax.bar(x, y, label='failures per voltklasse', align='center')\n",
    "ax.set_title('Aantal failures per volt klasse')\n",
    "ax.set_ylabel('Aantal failures')\n",
    "ax.set_xlabel('Voltklasse (V)')\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Failures over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=dfFailures\n",
    "df['datetime'] = pd.to_datetime(df['datetime']) \n",
    "# Maakt een nieuwe kolom aan (maand)\n",
    "df['month'] = df['datetime'].dt.month \n",
    "# Maakt een nieuwe kolom aan genaamd (week)\n",
    "df[\"week\"] = df['datetime'].dt.dayofweek \n",
    "# Maakt een nieuwe kolom aan (dag)\n",
    "df['day'] = df['datetime'].dt.day \n",
    "# Maakt een nieuwe kolom aan (uur)    \n",
    "df['hour'] = df['datetime'].dt.hour   \n",
    "## Drops original datetime col. \n",
    "# df = df.drop(['datetime'], axis=1) \n",
    "\n",
    "failureGroupVoltdf = dfSmall['failure'].groupby(dfSmall['month']).sum().reset_index()\n",
    "x = failureGroupVoltdf['month']\n",
    "y = failureGroupVoltdf['failure']\n",
    "\n",
    "figure = plt.figure(figzise=(8, 4))\n",
    "ax1 = plt.subplot(111)\n",
    "ax1.plot(x, y)\n",
    "plt.show()\n",
    "\n",
    "# figure,ax=plt.subplots(1, 2, figsize=(20,10))\n",
    "# df['Month'][df[\"failure\"]==1].value_counts().sort_index().plot(ax=ax[0])\n",
    "# ax[0].set_title('Maanden afgezet tegen failures')\n",
    "# ax[0].set_ylabel('Aantal failures')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "01ab45f3ee86d7021ac4a7b632c3bd0a262d7b9f8d2eee48d079bad2876dad4c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
