{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Maintenance\n",
    "\n",
    "## Inleiding\n",
    "\n",
    "**Auteurs:** *R. Coenen, Y. Dera, M. Vliex & S. van Wesel* <br>\n",
    "\n",
    "## Inhoudsopgave\n",
    "\n",
    "* [1. Business Understanding](#Chapter1)\n",
    "* [2. Data mining](#Chapter2)\n",
    "* [3. Data Cleaning](#Chapter3)\n",
    "* [4. Data Exploration](#Chapter4)\n",
    "* [5. Feature Engineering](#Chapter5)\n",
    "* [6. Predictive Modeling](#Chapter6)\n",
    "* [7. Data visualization](#Chapter7)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Business Understanding <a class=\"anchor\" id=\"Chapter1\"></a><br>\n",
    "**Stel relevante vragen en definieer doelstellingen voor het probleem dat moet worden aangepakt.** <br>\n",
    "\n",
    "**1.1 Over dit hoofdstuk:** <br>\n",
    "In deze fase is het belangrijk om begrip te krijgen voor de probleemstelling van de klant. Het overzichtelijk in kaart brengen van de wens van de opdrachtgever kan er in resulteren dat de gegevens beter begrepen worden en dat de juisite zinvolle inzichten uit de gegevens afgeleid zullen worden. In deze fase wordt de doelstelling van het project gedefinieerd en wordt omschreven welke voorspellingen uitgewerkt moeten worden. \n",
    "\n",
    "**1.2 De situatie** <br>\n",
    "De opdrachtgever van dit project heeft aan de projectgroep de opdracht verstrekt om een dataset te zoeken die gebruikt kan worden om voorspellingen te doen inzake het onderhoud van machines, deze methodiek heet predictive maintenance.. Het idee achter predictive maintenance is dat door het monitoren van apparatuur/machines met sensoren de life (of fail) cycle gemanaged kan worden en zo uitval van machines op tijd aangepakt\n",
    "kan worden; dit is dan ook gelijk de hoofdvraag van dit project. De vertaalslag van sensor data naar een predictie over bijvoorbeeld de resterende levensduur van een apparaat is echter moeilijk en hierbij komen verschillende technieken uit de datascience en machine learning hoek aan te pas. Aan de projectgroep de taak deze vertaalslag te maken en middels verschillende methodieken uit te werken.\n",
    "\n",
    "Predictive maintenance is een techniek welke gebruik maakt van data analyse tools en technieken om afwijkingen in een organisatie en mogelijke gebreken in apparatuur en processen vroegtijdig te detecteren zodat deze afgehandeld kunnen worden nog vóór dat deze resulteren in een fout {1}. Enerzijds focust predictive maintenance zich op het voorkomen van reactive maintenance {2}, waarbij het anderzijds de kosten voor preventive maintenance {3} probeert te verlagen.\n",
    "\n",
    "Ter verduidelijking, er zijn een drietal vormen van predictive maintenance:\n",
    "\n",
    "<b>Reactive (reactief)</b> - Onderhoud uitvoeren zodra er een probleem is<br>\n",
    "Probleem: onverwachte storingen kunnen duur (kosten) en potentieel gevaarlijk zijn\n",
    "\n",
    "<b>Scheuduled (gepland)</b> - Onderhoud uitvoeren op basis van een (regelmatig) schema<br>\n",
    "Probleem: onnodig onderhoud kan verspilling zijn; mogelijk worden niet alle storingen verholpen\n",
    "\n",
    "<b>Predictive (voorspellend)</b> - Voorspellen wanneer zich problemen zullen voordoen<br>\n",
    "Probleem: moeilijk om nauwkeurige voorspellingen te doen voor complexe apparatuur\n",
    "\n",
    "**1.3 Doelstelling** <br>\n",
    "De casusgroep zal op basis van onderzoek een realisatie maken van een pipeline die gaat van ruwe data naar een predictie model.\n",
    "\n",
    "**1.4 Resultaat** <br>\n",
    "Een dataset en bijbehordende pipeline (i.c.m. Python scripts in Jupyter notebook vorm) voor predictive maintenance.\n",
    "\n",
    "**1.5 Hoofdvraag** <br>\n",
    "Hoe kan predictive maintenance er voor zorgen, met behulp van monitoring van apparatuur/machines/sensoren, dat de life (of fail) cycle van een machine gemanaged kan worden en zo de uitval van machines op tijd aangepakt worden.\n",
    "\n",
    "**1.6 Deelvraag** <br>\n",
    "Is het mogelijk om de data in te zetten om een predictie te krijgen van de resterende levensduur van een apparaat?\n",
    "\n",
    "**1.7 Hypotheses** <br>\n",
    "- Is het mogelijk te voorspelen welke onderdelen in de toekomst zullen falen? \n",
    "- Is het mogelijk om, middels het gebruik van labels (classificatie) meerdere klassen aan te maken met een status inzake de gezondheid van de machines/componenten. Denk bijv. aan \"normaal\", \"onderhoud gewenst\", \"onderhoud kritiek\" etc.\n",
    "\n",
    "**1.8 Tools** <br>\n",
    "Er zijn diverse tools die ingezet zijn bij de realisatie van dit onderzoeksrapport. Deze worden hieronder in de tabel weergeven, inclusief een (beknopte) omschrijving.<br>\n",
    "De modules voor Python zijn in het hoorcollege en discussiecollege van week 4 aan bod gekomen.\n",
    "\n",
    "| Naam              | Soort | Omschrijving | Meer informatie\n",
    "| :----:            | :----:                     | :----:            | :----: |\n",
    "| Python            | Programmeertaal            | Python is een open-source programeertaal welke vaak gebruikt wordt voor machine learning | [Link](#https://www.python.org/) |\n",
    "| NumPy             | Module voor Python         | Module voor het omgaan met arrays en matrices met de bijbehorende functies               | [Link](#https://numpy.org/)      |\n",
    "| Matplotlib        | Module voor Python         | Module voor grafische toepassingen en visualisaties                                      | [Link](#https://matplotlib.org/) |\n",
    "| Seaborn           | Module voor Python         | Module voor high-level visualisaties                                                     | [Link](#https://seaborn.pydata.org/) |\n",
    "| Pandas            | Module voor Python         | Module voor het opslaan en manipuleren van datastructuren                                | [Link](#https://pandas.pydata.org/) |\n",
    "| Scikit-learn      | Module voor Python         | Module voor het toepassen van machine-learningtechnieken                                 | [Link](#https://www.python.org/) |\n",
    "| Anaconda          | Module voor Python         | Softwaresuite die o.a. Python en diverse (bovengenoemde) libraries, inzake data science, machine learning en data processing, bevat | [Link](#https://www.anaconda.com/products/individual) |\n",
    "| Jupyter Notebook  | (Web-based) Tekstverwerker | Online IDE waarmee Jupyter Notebooks (een variant op markdown bestanden) geschreven kunnen worden, in combinatie met Python programmacode | [Link](#https://jupyter.org/) \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Mining <a class=\"anchor\" id=\"Chapter2\"></a><br>\n",
    "**Verzamel en schrap de gegevens die nodig zijn voor het project.**\n",
    "\n",
    "**Over dit hoofdstuk:** <br>\n",
    "In deze fase wordt er een dataset verkregen. Deze dataset kan afkomstig zijn van verschillende bronnen (relationele en niet-relationele databases) en/of formaten (zoals spreadsheets, CSV, tekstbestanden). <br>\n",
    "\n",
    "Datamining is het proces van het verzamelen van de gegevens uit de verschillende bronnen. Deze fase gaat vooraf aan het groeperen en opschonen van gegevens. In deze fase wordt er na gedacht over welke gegevens relevant/nodig zijn voor het project, waar deze te vinden zijn, hoe deze verkregen kan worden en waar deze opgeslagen zal worden om mee aan de slag te gaan.\n",
    "\n",
    "**Stap 1: Welke gegevens zijn relevant voor dit project?** <br>\n",
    "In de opdrachtomschrijving van de opdrachtgever werd er gevraagd naar het voorspellen van onderhoudsmomenten voor machines, op basis van sensoren. Hierdoor zou uitval van de machines vroegtijdig aangepakt kunnen worden en eventueel de resterende levensduur in kaart gebracht worden. In dit geval is de sensordata aanwezig, onderhoudshistorie en informatie inzake failures en errors.\n",
    "\n",
    "**Stap 2: Waar zijn deze gegevens te vinden?** <br>\n",
    "De dataset waarmee gewerkt wordt in dit project is te raadplegen op [Kaggle](https://www.kaggle.com/arnabbiswas1/microsoft-azure-predictive-maintenance). Kaggle is een dochteronderneming van [Google](https://www.google.com/) en is een online platform/community, gericht op datawetenschappers en beoefenaars van machine learning. Deze website biedt gebruikers de mogelijkheid om datasets te vinden en te publiceren evenals dat gebruikers de mogelijkheid hebben om direct aan de slag te kunnen gaan met de datasets. \n",
    "\n",
    "De 'Microsoft Azure Predictive Maintenance' wordt voor dit project dus gedownload vanaf Kaggle. Deze dataset is echter in het verleden beschikbaar gesteld door [Microsoft](https://www.microsoft.com/) als een project onder de noemer 'Azure AI Notebooks for Predictive Maintenance'. Dit project is echter op 15 oktober 2020 beëindigd{1}. De dataset is via Kaggle wel nog te downloaden.\n",
    "\n",
    "**Stap 3: Hoe kan deze data verkregen worden?** <br>\n",
    "Via Kaggle zijn de 5, destijds door Microsoft beschikbaar gestelde, gegevens te vinden. Deze zijn opgeslagen en gepubliceerd in een CSV-formaat (kommagescheiden bestand). Deze dataset bestaat uit 5 delen: errors (1), failures (2), machines (3), maint (4) en telemtry (5). \n",
    "\n",
    "**Stap 4: Waar wordt de data opgeslagen (zodat er mee gewerkt kan worden)?** <br>\n",
    "Er wordt een centrale [GitHub](https://www.github.com/) omgeving aangemaakt waarbinnen de datasets worden opgeslagen. Deze omgeving biedt ook de mogelijkheid om het onderzoeksrapport te uploaden en de verschillende versies van de verschillende projectleden bij te houden inclusief een versiehistorie en de mogelijkheid om alle nieuwe revisies samen te voegen tot één gezamelijk bestand.\n",
    "\n",
    "**Stap 5: Een blik werpen op de data** <br>\n",
    "De dataset bestaat uit de volgende gegevens:\n",
    "- **Machinecondities en gebruik**: De bedrijfsomstandigheden (de omstandigheden wanneer de machine aan staat) van een machine, b.v. gegevens verzameld van sensoren.\n",
    "- **Storingshistorie**: De storingshistorie van een machine of onderdeel binnen de machine.\n",
    "- **Onderhoudshistorie**: De reparatiehistorie van een machine, b.v. foutcodes, eerdere onderhoudsactiviteiten of vervanging van onderdelen.\n",
    "- **Machinekenmerken**: De kenmerken van een machine, b.v. merk en model, locatie etc.\n",
    "\n",
    "En bevat de volgende kenmerken:\n",
    "- **Telemetrie-tijdreeksgegevens (PdM_telemetry.csv)**: het bestaat uit het uurgemiddelde van spanning, rotatie, druk en trillingen verzameld van 100 machines voor het jaar 2015.\n",
    "- **Fout (PdM_errors.csv)**: Dit zijn fouten die de machines tegenkomen terwijl ze in bedrijf (actief) zijn. Aangezien deze fouten de machines niet afsluiten, worden deze niet als storingen beschouwd. De foutdatum en -tijden worden afgerond op het dichtstbijzijnde uur, aangezien de telemetriegegevens tegen een uurtarief worden verzameld.\n",
    "- **Onderhoud (PdM_maint.csv)**: Als een onderdeel van een machine wordt vervangen, wordt dat als record vastgelegd in deze tabel. Onderdelen worden vervangen in twee situaties: <br>\n",
    "1. Tijdens het reguliere geplande bezoek heeft de monteur het vervangen (Proactief Onderhoud) <br> \n",
    "2. Een onderdeel gaat kapot en vervolgens voert de monteur een ongepland onderhoud uit om het onderdeel te vervangen (Reactief Onderhoud). Dit wordt beschouwd als een storing en de bijbehorende gegevens worden vastgelegd onder Storingen. Onderhoudsgegevens hebben records voor zowel 2014 als 2015. Deze gegevens worden afgerond op het dichtstbijzijnde uur, aangezien de telemetriegegevens tegen een uurtarief worden verzameld.\n",
    "- **Storingen (PdM_failures.csv)**: Elk record vertegenwoordigt de vervanging van een onderdeel als gevolg van een storing. Deze gegevens zijn een subset van onderhoudsgegevens. Deze gegevens worden afgerond op het dichtstbijzijnde uur, aangezien de telemetriegegevens tegen een uurtarief worden verzameld.\n",
    "- **Metadata van machines (PdM_Machines.csv)**: modeltype en leeftijd van de machines.\n",
    "\n",
    "*Tabel 1: Data Dictionary*\n",
    "\n",
    "| Feature   | Omschrijving | Voorbeeld data    | Data Type | Type variabele | Meeteenheid | (Oorspronkelijke) databron |\n",
    "| ----------| -------------| ----------------- | ----------| ---------------| ------------|  --------------------------|\n",
    "| machineID | Iedere machine wordt gekenmerkt door een uniek identificatienummer | 1 | Int64 | Kwalitatief (discreet) | n.v.t | PdM_machines.csv |\n",
    "| model     | Er zijn verschillende soorten modellen, die gekenmerkt worden door een modelnummer | model 3 | text | Kwalitatief (discreet) | n.v.t |PdM_machines.csv |\n",
    "| age       | De leeftijd van de machines/compontenten | 18 | Int64 | Kwantitatief (discreet) | Maanden | PdM_machines.csv |\n",
    "| datetime  | Geeft de datum en tijd weer | 3-1-2015 07:00:00 | datetime | Kwantitatief (continue) | Uren, minuten, seconde | PdM_errors.csv     |\n",
    "| errorID   | Iedere error wordt gekenmerkt door een (uniek) error nummer | error1 | text | Kwalitatief (discreet) | n.v.t | PdM_errors.csv     |\n",
    "| failure   | Geeft aan welk component gefaald is | comp4 | text | Kwalitatief (discreet) | Binair | PdM_failures.csv |\n",
    "| comp      | Ieder component wordt gekenmerkt door een componentnummer | comp2 | text | Kwalitatief (discreet) | n.v.t | PdM_maint.csv |\n",
    "| volt      | De elektrische spanning in volt | 176217853015625 | Int64 | Kwantitatief (continue)| voltage ($V$) | PdM_maint.csv |\n",
    "| rotate    | Aantal rotaties per minuut | 418504078221616   | Int64 | Kwantitatief (continue) | Rotaties per minuut ($RPM$) | PdM_maint.csv  |\n",
    "| pressure  | Uitgeoefende druk in Kilo pascal (=0,01 bar) | 113077935462083   | Int64 | Kwantitatief (continue) | Kilo Pascal ($kPa$) (1 kPa = 0,01 bar) | PdM_maint.csv  |\n",
    "| vibration | Periodieke beweging van een voorwerp of medium | 450876857639276 | Int64 | Kwantitatief (continue) | Herz ($Hz$) | PdM_maint.csv |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In onderstaande code wordt, op een simplistische wijze, een beperkte inkijk gegeven in de data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Het importeren van de benodigde bilbiotheken\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Het inlezen van de bestanden\n",
    "telemetry_df = pd.read_csv('PdM_telemetry.csv')\n",
    "errors_df = pd.read_csv('PdM_errors.csv')\n",
    "maint_df = pd.read_csv('PdM_maint.csv')\n",
    "failures_df = pd.read_csv('PdM_failures.csv')\n",
    "machines_df = pd.read_csv('PdM_machines.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>machineID</th>\n",
       "      <th>volt</th>\n",
       "      <th>rotate</th>\n",
       "      <th>pressure</th>\n",
       "      <th>vibration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>176.217853</td>\n",
       "      <td>418.504078</td>\n",
       "      <td>113.077935</td>\n",
       "      <td>45.087686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01 07:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>162.879223</td>\n",
       "      <td>402.747490</td>\n",
       "      <td>95.460525</td>\n",
       "      <td>43.413973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01 08:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>170.989902</td>\n",
       "      <td>527.349825</td>\n",
       "      <td>75.237905</td>\n",
       "      <td>34.178847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01 09:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>162.462833</td>\n",
       "      <td>346.149335</td>\n",
       "      <td>109.248561</td>\n",
       "      <td>41.122144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01 10:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>157.610021</td>\n",
       "      <td>435.376873</td>\n",
       "      <td>111.886648</td>\n",
       "      <td>25.990511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  machineID        volt      rotate    pressure  \\\n",
       "0  2015-01-01 06:00:00          1  176.217853  418.504078  113.077935   \n",
       "1  2015-01-01 07:00:00          1  162.879223  402.747490   95.460525   \n",
       "2  2015-01-01 08:00:00          1  170.989902  527.349825   75.237905   \n",
       "3  2015-01-01 09:00:00          1  162.462833  346.149335  109.248561   \n",
       "4  2015-01-01 10:00:00          1  157.610021  435.376873  111.886648   \n",
       "\n",
       "   vibration  \n",
       "0  45.087686  \n",
       "1  43.413973  \n",
       "2  34.178847  \n",
       "3  41.122144  \n",
       "4  25.990511  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Het tonen van de data (standaard toont de .head functie de eerste 5 rijen van de code) \n",
    "telemetry_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>machineID</th>\n",
       "      <th>errorID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-03 07:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>error1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-03 20:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>error3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-04 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>error5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-10 15:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>error4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-22 10:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>error4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  machineID errorID\n",
       "0  2015-01-03 07:00:00          1  error1\n",
       "1  2015-01-03 20:00:00          1  error3\n",
       "2  2015-01-04 06:00:00          1  error5\n",
       "3  2015-01-10 15:00:00          1  error4\n",
       "4  2015-01-22 10:00:00          1  error4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Het tonen van de data (standaard toont de .head functie de eerste 5 rijen van de code) \n",
    "errors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>machineID</th>\n",
       "      <th>comp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-06-01 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>comp2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-07-16 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>comp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-07-31 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>comp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-12-13 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>comp1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-05 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>comp4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  machineID   comp\n",
       "0  2014-06-01 06:00:00          1  comp2\n",
       "1  2014-07-16 06:00:00          1  comp4\n",
       "2  2014-07-31 06:00:00          1  comp3\n",
       "3  2014-12-13 06:00:00          1  comp1\n",
       "4  2015-01-05 06:00:00          1  comp4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Het tonen van de data (standaard toont de .head functie de eerste 5 rijen van de code) \n",
    "maint_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>machineID</th>\n",
       "      <th>failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-05 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>comp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-03-06 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>comp1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-04-20 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>comp2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-06-19 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>comp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-09-02 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>comp4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  machineID failure\n",
       "0  2015-01-05 06:00:00          1   comp4\n",
       "1  2015-03-06 06:00:00          1   comp1\n",
       "2  2015-04-20 06:00:00          1   comp2\n",
       "3  2015-06-19 06:00:00          1   comp4\n",
       "4  2015-09-02 06:00:00          1   comp4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Het tonen van de data (standaard toont de .head functie de eerste 5 rijen van de code) \n",
    "failures_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>machineID</th>\n",
       "      <th>model</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>model3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>model4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>model3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>model3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>model3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   machineID   model  age\n",
       "0          1  model3   18\n",
       "1          2  model4    7\n",
       "2          3  model3    8\n",
       "3          4  model3    7\n",
       "4          5  model3    2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Het tonen van de data (standaard toont de .head functie de eerste 5 rijen van de code) \n",
    "machines_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bovenstaande dataframes worden op een later moment samengevoegd tot één dataframe (zie hoofdstuk 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(876100, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Het vertonen van het aantal rijen en het aantal kolommen\n",
    "telemetry_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoals te zien zijn er maarliefst 876.100 records aanwezig in de telemetrie logfiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telemetry_df.machineID.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deze zijn verzameld over 100 machines, zoals hierboven weergegeven."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Cleaning <a class=\"anchor\" id=\"Chapter3\"></a><br>\n",
    "Dit hoofdstuk gaat in op het gereed maken van de dataset. Oorspronkelijk bestaat de dataset uit 5 losse csv bestanden die tot één document samengevoegd dient te worden. Het samenvoegen van het document gebeurd in de paragraaf [Data Wrangling](#Chapter3.1). Vervolgens worden stappen ondernomen om enerzijds vast te stellen of data cleaning benodigd is na het samenvoegen van de data en anderzijds deze zaken op te lossen. Dit is terug te vinden in [paragraaf 3.2.](#Chapter3.2). Zo bestaat dit hoofdstuk uit de twee grote componenten voor het gereedmaken van de data voordat deze verkend kan worden; \n",
    "+ *Data Wrangling*: Het samenvoegen van brondata tot één dataframe.\n",
    "+ *Data Cleaning*: Het identificeren van fouten in de data en deze afhandelen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Data Wrangling <a class=\"anchor\" id=\"Chapter3.1\"></a><br>\n",
    "Data wrangling betreft het op elkaar laten passen van de data. Hiermee wordt bedoelt het leggen van [relaties](https://www.techopedia.com/definition/21677/relation#:~:text=In%20relational%20databases%2C%20a%20relationship,key%20of%20the%20other%20table.&text=Relation%2C%20therefore%2C%20is%20the%20defining,also%20be%20known%20as%20relationship.) tussen de tabellen. Het samenvoegen van de bronnen volgt een aantal stappen. Deze worden onderverdeeld in stapnummers en parallel gedocumenteerd en uitgevoerd.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1. Data Wrangling stap 1 <a class=\"anchor\" id=\"Chapter3.1.1\"></a><br>\n",
    "De eerste stap voor het op elkaar laten passen is het inzichtelijk maken van het datamodel. Middels gebruik te maken van [Microsoft PowerBI](https://powerbi.microsoft.com/nl-nl/) wordt een model opgesteld waarbij de relaties tussen de tabellen geïdentificeerd kunnen worden. Dit heeft als resultaat het onderstaat Entity Attribute Relation Diagram (EARD):\n",
    "\n",
    "<img src=\"img/Oorspronkelijk_dataModel.png\" alt=\"oorspronkelijk datamodel\" width=\"650\"/><br>\n",
    "*Oorspronkelijk datamodel* <br>\n",
    "\n",
    "Onderstaande tabel omschrijft de relaties tussen de tabellen met een verdere diepgaande omschrijving om extra verheldering te bieden. \n",
    "\n",
    "*Relaties in model*\n",
    "|Tabel 1 (van)|Tabel 2 (naar)|Type relatie|Omschrijving|\n",
    "|:---:|:---:|---|---|\n",
    "|PDM_Machines|PDM_Maint|1 op 0 of meer (1...0*)|De relatie tussen de tabellen definieerd dat één machine 0 of meer keer onderhoud zal ondergaan|\n",
    "|PDM_Machines|PDM_Failures|1 op 0 of meer (1...0*)|De relatie tussen de tabellen definieerd dat één machine 0 of meer failures kan hebben|\n",
    "|PDM_Machines|PDM_Errors|1 op 0 of meer (1...0*)|De relatie tussen de tabellen definieerd dat één machine 0 of meer errors kan hebben|\n",
    "|PDM_Machines|PDM_Telemetry|1 op 1 of meer (1...1*)|De relatie tussen de tabellen definieerd dat één machine minstens één keer gemeten is in de operationele staat|\n",
    "\n",
    "Echter, op basis van diepgaander onderzoek blijkt dat de tabellen anders samengevoegd dienen te worden. Dit komt door een verschillende aantal opvallende zaken waarmee rekening gehouden dient te worden bij het samenvoegen van de bronbestanden. Deze opvallende zaken zijn: \n",
    "\n",
    "+ Een Error hoeft niet altijd tot een failure te leiden en dient gezien te worden als een aparte tabel. \n",
    "+ De tabellen PDM_Maint en PDM_Failures zijn aan elkaar gelinkt. Een failure leidt namenlijk altijd tot onderhoud. Maar onderhoud wordt niet alleen uitgevoerd door de gevolgen van een failure.\n",
    "\n",
    "Deze twee zaken dienen in acht genomen te worden bij de volgende stappen, dit zal uiteindelijk ook leiden tot een ander model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2. Data Wrangling stap 2 <a class=\"anchor\" id=\"Chapter3.1.2\"></a><br>\n",
    "Nu bekend is hoe data onderling is gerelateerd aan elkaar, is het van belang op basis van de opvallende zaken het gehele dataframe op te gaan bouwen. Hiervan is de eerste stap direct het afhandelen van de tweede opvallende zaak (relatie tussen failures en maintenance tabel). \n",
    "\n",
    "**1.**<br>\n",
    "De eerste samenvoeging wordt gedaan en krijgt de naam df1. df1 is een left join van de maintenance tabel op de failures tabel. Hierbij worden vanuit de PDM_Maint de kolommen ```datetime```, ```machineID``` en ```comp``` meegenomen. Vanuit de rechter tabel (PDM_failure) worden de kolommen ```datetime```, ```machineID``` en ```failure``` meegenomen. Hierbij is het mogelijk dat comp en failure op elkaar gejoined worden aangezien de inhoud van de rijen hetzelfde is. Een voorbeeld van de inhoud van de [comp] is namenlijk \"comp4\", deze waarde kan ook terug komen in de kolom failure van PDM_failures. Onderstaande regel toont de code hiervoor. \n",
    "\n",
    "```df1 = pd.merge(dfMaint, dfFailures, how='left', left_on=['datetime', 'machineID', 'comp'], right_on = ['datetime', 'machineID', 'failure'])```\n",
    "\n",
    "**2.**<br>\n",
    "Nadat de tabellen zijn samengevoegd is het van belang de lege waardes (Nan) in de 'failure' kolom op te vullen met een 0. Dit wordt gedaan om aan te duiden dat wanneer er een 0 staat, er geen failure op heeft getreden. Dit wordt uitgevoerd met de regel: \n",
    "\n",
    "```df1['failure'] = df1['failure'].fillna(0)```\n",
    "\n",
    "**3.**<br>\n",
    "Vervolgens is het van belang dat wanneer er een failure op heeft getreden (de rijen in de kolom [failure] die een waarde hebben), deze waarde op 1 gezet wordt. Hiermee wordt de kolom [failure] omgezet naar een binaire waarde. Wanneer dit is uitgevoerd indiceert een '1' in de kolom [failure] een failure, en een '0' geen failure. Het corresponderende component wanneer een failure optradt, is te zien in de kolom [comp]. Om dit te verwezenlijken wordt de volgende regel code uitgevoerd: \n",
    "\n",
    "```df1.loc[((df1.failure == 'comp1') | (df1.failure == 'comp2') | (df1.failure == 'comp3') | (df1.failure == 'comp4')), 'failure'] = '1'```\n",
    "\n",
    "**4.**<br>\n",
    "Vervolgens wordt in een laatste sub-stap een regel code uitgevoerd om de datatype kolom [failure] om te zetten naar een integer datatype. Dit wordt gedaan om er later berekeningen over te kunnen doen. \n",
    "\n",
    "```df1['failure'] = df1['failure'].astype(int)```\n",
    "\n",
    "Alle stappen worden in onderstaande codeblock uitgevoerd. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Left join failures on maintenance to create df1\n",
    "df1 = pd.merge(dfMaint, dfFailures, how='left', left_on=['datetime', 'machineID', 'comp'], right_on = ['datetime', 'machineID', 'failure'])\n",
    "df1['failure'] = df1['failure'].fillna(0) #indicates maint was not a failure\n",
    "df1.loc[((df1.failure == 'comp1') | (df1.failure == 'comp2') | (df1.failure == 'comp3') | (df1.failure == 'comp4')), 'failure'] = '1' #indicates maintenance was a failure\n",
    "df1['failure'] = df1['failure'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3. Data Wrangling stap 3 <a class=\"anchor\" id=\"Chapter3.1.3\"></a><br>\n",
    "De volgende stap in het samenvoegen van de dataset betreft het gereed maken van de Error tabel. De Error tabel voegt per error een nieuwe rij toe wat resulteert in redundante data. Een voorbeeld hiervan is bijvoorbeeld:\n",
    "\n",
    "|datetime|machineID|errorID|\n",
    "|---|---|---|\n",
    "|7/18/2020 : 06:00:00|1|error1|\n",
    "|7/18/2020 : 06:00:00|1|error2|\n",
    "\n",
    "De twee rijen in de tabel worden redundant gezien op basis van de datetime en machineID. Het kan dus voorkomen dat een machine op één tijdstip meerdere errors krijgt. Om dit af te handelen worden een aantal stappen uitgevoerd. \n",
    "\n",
    "**1.** <br>\n",
    "De eerste stap van het gereed maken van de errors tabel is het toekennen van het oorspronkelijke dataframe aan df2. Hierna worden vijf nieuwe kolommen aangemaakt met de namen *Error1*, *Error2*, *Error3*, *Error4* en *Error5*. De waardes voor deze kolommen worden vervolgens allemaal op *0* gezet. Onderstaande code zorgt ervoor dat dit gerealiseerd wordt: \n",
    "\n",
    "```python\n",
    "df2 = dfErrors\n",
    "df2['Error1'] = 0\n",
    "df2['Error2'] = 0\n",
    "df2['Error3'] = 0\n",
    "df2['Error4'] = 0\n",
    "df2['Error5'] = 0\n",
    "```\n",
    "**2.** <br>\n",
    "De volgende stap in het gereedmaken van de error tabel (vanaf nu df2 genoemd) is het lokaliseren van de errorwaardes in de *errorID* kolom. Vervolgens wordt aan de bijpassende kolom waarde *1* toegevoegd. Op deze manier ontstaat een binaire waarde in een kolom. Dit betekent dat de rijen uit het eerdere voorbeeld er als volgt uit komen te zien: \n",
    "\n",
    "|datetime|machineID|errorID|Error1|Error2|Error3|Error4|Error5\n",
    "|---|---|---|---|---|---|---|---|\n",
    "|7/18/2020 : 06:00:00|1|error1|1|0|0|0|0|\n",
    "|7/18/2020 : 06:00:00|1|error2|0|1|0|0|0|\n",
    "\n",
    "Om dit te verwezenlijken wordt het onderstaande stuk code uitgevoerd: \n",
    "\n",
    "```python\n",
    "df2.loc[(df2['errorID'] == 'error1'), 'Error1'] = 1\n",
    "df2.loc[(df2['errorID'] == 'error2'), 'Error2'] = 1\n",
    "df2.loc[(df2['errorID'] == 'error3'), 'Error3'] = 1\n",
    "df2.loc[(df2['errorID'] == 'error4'), 'Error4'] = 1\n",
    "df2.loc[(df2['errorID'] == 'error5'), 'Error5'] = 1\n",
    "```\n",
    "\n",
    "**3.** <br>\n",
    "De derde stap is het groeperen van de rijen waarin de rijen alsnog dubbel staan. In de voorbeeldtabel is te zien dat de rijen nog steeds dubbel staan. Dit wordt middels een groupby afgehandeld op basis van de *datetime* en *machineID* kolom. Dit zal gebeuren voor iedere Error{n} kolom met een lengte van 5. Hiervoor zal de som opgeteld worden. Dit wordt verwezenlijkt middels onderstaande regel code. \n",
    "\n",
    "```python\n",
    "df2 = df2.groupby(['datetime', 'machineID'])[[f'Error{n}' for n in range (1,6)]].sum() \n",
    "```\n",
    "\n",
    "Alle stappen worden in onderstaand codeblock uitgevoerd. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean error table to create df2, df2 = cleansed dfErrors tbl. \n",
    "df2 = dfErrors\n",
    "df2['Error1'] = 0\n",
    "df2['Error2'] = 0\n",
    "df2['Error3'] = 0\n",
    "df2['Error4'] = 0\n",
    "df2['Error5'] = 0\n",
    "\n",
    "df2.loc[(df2['errorID'] == 'error1'), 'Error1'] = 1\n",
    "df2.loc[(df2['errorID'] == 'error2'), 'Error2'] = 1\n",
    "df2.loc[(df2['errorID'] == 'error3'), 'Error3'] = 1\n",
    "df2.loc[(df2['errorID'] == 'error4'), 'Error4'] = 1\n",
    "df2.loc[(df2['errorID'] == 'error5'), 'Error5'] = 1\n",
    "\n",
    "# # df2 = df2.groupby(['machineID', 'datetime']).sum() #Groups on all cols.\n",
    "df2 = df2.groupby(['datetime', 'machineID'])[[f'Error{n}' for n in range (1,6)]].sum() #Groups errorID cols only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.4. Data Wrangling stap 4 <a class=\"anchor\" id=\"Chapter3.1.4\"></a><br>\n",
    "De vierde stap betreft het samenvoegen van de *telemtry* tabel in *df2* (zojuist gereed gemaakte error tabel) Ook hier worden een aantal onderliggende stappen uitgevoerd om te komen tot *df3*. \n",
    "\n",
    "**1.** <br>\n",
    "De eerste stap betreft het mergen van dfTelemetry met df2 om te komen tot df3. Dit wordt gedaan door een left join van dfTelemetry op df2 te doen. Hierbij worden op de kolommen *machineID* en *datetime* gekoppeld die in beiden voorkomen. Deze join zorgt ervoor dat alle rijen uit de dfTelemetry meegenomen worden en hieraan de df2 rijen en kolommen aan toe worden gevoegd. \n",
    "\n",
    "```python\n",
    "df3 = pd.merge(dfTelemetry, df2, how='left', left_on=['machineID', 'datetime'], right_on=['machineID', 'datetime'])\n",
    "```\n",
    "\n",
    "Dit leidt tot de volgende handelingen die gedaan dient te worden. Wanneer nu df3 wordt bekeken ontstaat er namelijk het volgende waarbij alle reeds aangemaakte kolommen (Error1 t/m 5) weer op NaN zijn gezet: \n",
    "\n",
    "|datetime|machineID|volt|rotate|pressure|vibration|Error1|Error2|Error3|Error4|Error5|\n",
    "|---|---|---|---|---|---|---|---|---|---|---|\n",
    "|2015-01-01 06:00:00|1|176.217853|418.504078|113.077935|45.087686|NaN|NaN|NaN|NaN|NaN|\n",
    "|2015-01-01 07:00:00|1|162.879223|402.747490|95.460525|43.413973|NaN|NaN|NaN|NaN|NaN|\n",
    "\n",
    "**2.** <br>\n",
    "Het afhandelen van de NaN waardes gebeurd in 5 regels code waarbij iedere Error{x} wordt gevuld met een *0*. Dit gebeurd middels onderstaande code:\n",
    "\n",
    "```python\n",
    "df3['Error1'] = df3['Error1'].fillna(0)\n",
    "df3['Error2'] = df3['Error2'].fillna(0)\n",
    "df3['Error3'] = df3['Error3'].fillna(0)\n",
    "df3['Error4'] = df3['Error4'].fillna(0)\n",
    "df3['Error5'] = df3['Error5'].fillna(0)\n",
    "```\n",
    "\n",
    "**3.** <br>\n",
    "De laatste handeling die betreffende df3 gedaan dient te worden is het omzetten van het datatype naar een integer. Momenteel is het een object (string) door het samenvoegen van de dataframes. Middels onderstaande code worden de datatypes (dtypes) voor alle Error{x} kolommen omgezet naar een integer(32)\n",
    "\n",
    "```python\n",
    "df3.Error1 = df3.Error1.astype(int)\n",
    "df3.Error2 = df3.Error2.astype(int)\n",
    "df3.Error3 = df3.Error3.astype(int)\n",
    "df3.Error4 = df3.Error4.astype(int)\n",
    "df3.Error5 = df3.Error5.astype(int)\n",
    "```\n",
    "\n",
    "Dit leidt tot een voorbeeldtabel als (waarbij de kolommen Error1, Error2, Error3, Error4 en Error5 het datatype integer(32) hebben gekregen):\n",
    "\n",
    "|datetime|machineID|volt|rotate|pressure|vibration|Error1|Error2|Error3|Error4|Error5|\n",
    "|---|---|---|---|---|---|---|---|---|---|---|\n",
    "|2015-01-01 06:00:00|1|176.217853|418.504078|113.077935|45.087686|1|0|0|0|0|\n",
    "|2015-01-01 07:00:00|1|162.879223|402.747490|95.460525|43.413973|0|1|0|0|0|\n",
    "\n",
    "Alle code wordt in onderstaande codeblock uitgevoerd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create df3 by joining dfTelemetry on df2\n",
    "df3 = pd.merge(dfTelemetry, df2, how='left', left_on=['machineID', 'datetime'], right_on=['machineID', 'datetime'])\n",
    "\n",
    "df3['Error1'] = df3['Error1'].fillna(0)\n",
    "df3['Error2'] = df3['Error2'].fillna(0)\n",
    "df3['Error3'] = df3['Error3'].fillna(0)\n",
    "df3['Error4'] = df3['Error4'].fillna(0)\n",
    "df3['Error5'] = df3['Error5'].fillna(0)\n",
    "\n",
    "df3.Error1 = df3.Error1.astype(int)\n",
    "df3.Error2 = df3.Error2.astype(int)\n",
    "df3.Error3 = df3.Error3.astype(int)\n",
    "df3.Error4 = df3.Error4.astype(int)\n",
    "df3.Error5 = df3.Error5.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.5. Data Wrangling stap 5 <a class=\"anchor\" id=\"Chapter3.1.5\"></a><br>\n",
    "De vijfde stap betreft het samenvoegen van de zojuist aangemaakte df3 op de machines tabel. Dit betreft een relatief gemakkelijke merge die wordt gedaan middels een right join van machines op df3. Hiermee worden alle rijen van de oorspronkelijke dfTelemetry bewaard en worden de kolommen model en age vanuit de tabel machines toegevoegd. Deze join wordt gedaan enkel op de sleutel *machineID* aangezien dit de enige kolom is die beiden dataframes hebben. Onderstaande code voert dit uit gevolgd met het daaronder staande vooebeeld:\n",
    "\n",
    "```python\n",
    "df4 = pd.merge(dfMachines, df3, how='right', left_on=['machineID'], right_on=['machineID'])\n",
    "```\n",
    "\n",
    "\n",
    "|machineID|model|age|datetime|volt|rotate|pressure|vibration|Error1|Error2|Error3|Error4|Error5|\n",
    "|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
    "|1|model3|18|2015-01-01 06:00:00|176.217853|418.504078|113.077935|45.087686|1|0|0|0|0|\n",
    "|1|model3|18|2015-01-01 07:00:00|162.879223|402.747490|95.460525|43.413973|0|1|0|0|0|\n",
    "\n",
    "Alle code wordt in onderstaand codeblock uitgevoerd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create df4 by joining machines on df3\n",
    "df4 = pd.merge(dfMachines, df3, how='right', left_on=['machineID'], right_on=['machineID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.6. Data Wrangling stap 6 <a class=\"anchor\" id=\"Chapter3.1.6\"></a><br>\n",
    "De zesde stap is het aanmaken van de volledige dataset. Op dit punt zijn de drie linkse tabellen samengevoegd tot df4 en de twee rechtse tabellen tot df1. df5 wordt de samenvoeging van deze twee dataframes waarbij een right join van df1 op df4 wordt gedaan op basis van de kolommen *machineID* en *datetime*. Hiermee worden alle oorspronkelijke rijen van de oude dataset dfTelemetry bewaard (zie code). \n",
    "\n",
    "```python\n",
    "df5 = pd.merge(df1, df4, how='right', left_on=['machineID', 'datetime'], right_on=['machineID', 'datetime'])\n",
    "```\n",
    "\n",
    "Echter is het mogelijk dat hier problemen ontstaan doordat er veel lege waardes in de *comp* en *failure* kolom ontstaan, dit is terug te zien in het onderstaande voorbeeld: \n",
    "\n",
    "|datetime|machineID|comp|failure|model|age|volt|rotate|pressure|vibration|Error1|Error2|Error3|Error4|Error5|\n",
    "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
    "|2015-01-01 06:00:00|1|comp4|1|model3|18|179.303153|499.777962|111.833028|52.383097|0|0|0|0|0|\n",
    "|2015-01-01 07:00:00|1|comp1|0|model3|18|179.303153|499.777962|111.833028|52.383097|0|0|0|0|0|\n",
    "|2016-01-01 02:00:00|100|NaN|NaN|model4|5|179.438162|395.222827|102.290715|50.771941|0|0|0|0|0|\n",
    "|2016-01-01 07:00:00|100|NaN|NaN|model4|5|189.617555|446.207972|98.180607|35.123072|0|0|0|0|0|\n",
    "\n",
    "Om problemen te voorkomen wordt een alternatieve dataset opgebouwd die is gefocust op een kleinere dataframe. Dit wordt in de volgende stap afgehandeld.\n",
    "\n",
    "Alle code wordt in onderstaand codeblock uitgevoerd. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create df5 by joining df1 on df4\n",
    "df5 = pd.merge(df1, df4, how='right', left_on=['machineID', 'datetime'], right_on=['machineID', 'datetime'])\n",
    "df = df5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.7. Data Wrangling stap 7 <a class=\"anchor\" id=\"Chapter3.1.7\"></a><br>\n",
    "Om het zojuist opgedane \"probleem\" te verhelpen, wordt een kleinere dataframe opgebouwd op dezelfde wijze als df5 is ontwikkeld. Echter wordt er nu gebruik gemaakt van een inner join zodat er geen lege waardes in kolommen zullen voorkomen. Dit resulteert tevens in een kleinere dataset met slechts(!) 2886 rijen. Deze zogenoemende dfSmall dataframe wordt uitgevoerd middels de regel code: \n",
    "\n",
    "```python\n",
    "dfSmall = pd.merge(df1, df4)\n",
    "```\n",
    "\n",
    "Hiermee ontstaat het volgende: \n",
    "\n",
    "|datetime|machineID|comp|failure|model|age|volt|rotate|pressure|vibration|Error1|Error2|Error3|Error4|Error5|\n",
    "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
    "|2015-01-01 06:00:00|1|comp4|1|model3|18|179.303153|499.777962|111.833028|52.383097|0|0|0|0|0|\n",
    "|2015-01-01 07:00:00|1|comp1|0|model3|18|179.303153|499.777962|111.833028|52.383097|0|0|0|0|0|\n",
    "|2015-12-09 06:00:00|100|comp2|1|model4|5|144.720190|377.188361|109.995936|28.433400|0|0|0|0|0|\n",
    "|2015-12-24 06:00:00|100|comp2|0|model4|5|154.408466|535.776651|102.614263|30.723456|0|0|0|0|0|\n",
    "\n",
    "alle code wordt in onderstaand codeblock uitgevoerd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dfSmall by inner joining df1 on df4\n",
    "dfSmall = pd.merge(df1, df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Data Cleaning <a class=\"anchor\" id=\"Chapter3.2\"></a><br>\n",
    "**Identificatie van fouten** <br>\n",
    "Data cleaning betreft het proces voor het schoonmaken van de data waarbij op een aantal zaken wordt gelet. Aan de hand van [deze website](https://www.analyticsvidhya.com/blog/2021/06/data-cleaning-using-pandas/) worden verschillende stappen code uitgevoerd om inzicht te krijgen in de data en hoe schoon deze data is. Middels onderstaande regels code worden de eerste inzichten verkregen in de (lege) waardes van de data. Wanneer hier opvallende zaken optreden is het van belang deze af te handelen.\n",
    "\n",
    "```python\n",
    "df.head()\n",
    "df.tail()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isna().any())\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data Exploration <a class=\"anchor\" id=\"Chapter4\"></a><br>\n",
    "In dit hoofdstuk worden verschillende verwachtingen vanuit het perspectief van de dataset geformuleerd. Deze verwachtingen zijn gebaseerd op de kennis over de data die in voorgaande hoofdstukken is opgedaan. De verwachtingen worden in een later stadium bevestigd middels de realisatie van machine learning modellen.\n",
    "\n",
    "Om de verwachtingen te onderbouwen wordt gebruik gemaakt van een correlatie heatmap, visualisaties over de data en waar nodig literatuur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Verwachtingen <a class=\"anchor\" id=\"Hypothesen\"></a><br>\n",
    "In deze paragraaf worden de verwachtingen vanuit de data opgesteld. Eerder is in *paragraaf .....* de verwachting genoemd dat de operationele prestaties van de machines invloed hebben op de failures die bij de machines ontstaan. Deze verwachting wordt onderstaande uitgesplitst in meerdere sub-verwachtingen.\n",
    "\n",
    "**Sub-verwachtingen:**<br>\n",
    "1. Het voltage van de machines heeft invloed op het optreden van failures.\n",
    "2. De rotatie van/in de machines heeft invloed op het optreden van failures.\n",
    "3. De druk van/binnen de machines heeft invloed op het optreden van failures.\n",
    "4. De vibratie van de machines heeft invloed op het optreden van failures.\n",
    "\n",
    "Naast de hierboven genoemde sub-verwachtingen wordt ook verwacht dat: <br>\n",
    "1. De leeftijd van de machines invloed heeft op het optreden van failures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Correlatie heatmap\n",
    "Om het verband tussen de onafhankelijke features zoals bijvoorbeeld voltage en de afhankelijke feature \"failure\" in kaart te brengen wordt er een correlatie heatmap gerealiseerd. In de correlatie heatmap kan worden afgelezen of er een negatieve, positieve of geen correlatie (verband) aanwezig is tussen een onafhankelijke en afhankelijke feature. Middels het identificeren van correlaties wordt bekend of de onafhankelijke feature invloed heeft op de afhankelijke feature en kunnen de eerder beschreven verwachtingen onderbouwd worden.\n",
    "\n",
    "Voor elke verwachting, beschreven in de voorgaande paragraaf, wordt de correlatie tussen de onafhankelijke en afhankelijke feature inclusief de betekenis beschreven in onderstaande tabel. In de tabel wordt ook aangegeven hoe sterk of zwak een correlatie is. De identificatie hiervan is gebaseerd op een tabel uit de bron [Correlatie](https://www.scribbr.nl/statistiek/correlatie/).\n",
    "\n",
    "| Verwachting | Correlatie | Betekenis Correlatie |\n",
    "| :---------: | :--------: | :------------------: |\n",
    "| Voltage heeft invloed op failure | 0.11 | Het betreft hier een zeer lage positieve correlatie. Wanneer het voltage van een machine toeneemt zal ook de kans op een failure toenemen. |\n",
    "| Rotation heeft invloed op failure | - 0.19 | Het betreft hier een zeer lage negatieve correlatie. Wanneer de rotatie van/in een machine toeneemt zal de kans op een failure afnemen. |\n",
    "| Pressure heeft invloed op failure | 0.15 | Het betreft hier een zeer lage positieve correlatie. Wanneer de druk (pressure) van/binnen een machine toeneemt zal ook de kans op een failure toenemen. |\n",
    "| Vibration heeft invloed op failure | 0.20 | Het betreft hier een zeer lage positieve correlatie. Wanneer de vibratie van een machine toeneemt zal ook de kans op een failure toenemen. |\n",
    "| Age heeft invloed op failure | 0.13 | Het betreft een zeer lage positieve correlatie. Wanneer de leeftijd (age) van een machine toeneemt zal ook de kans op een failure toenemen |\n",
    "\n",
    "Op basis van de correlatie heatmap kan geconcludeerd worden dat voor iedere verwachting de onafhankelijke feature een lichte invloed heeft op de afhankelijke feature \"failure\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[15,8])\n",
    "sb.heatmap(df.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Visualisaties\n",
    "Om (visueel) meer inzicht te verkrijgen in de correlaties tussen de onafhankelijke features en de afhankelijke feature \"failure\" wordt voor elke verwachting een visualisatie gerealiseerd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. Additionele zaken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Feature Engineering <a class=\"anchor\" id=\"Chapter5\"></a><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Predictive Modeling <a class=\"anchor\" id=\"Chapter6\"></a><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Data visualization <a class=\"anchor\" id=\"Chapter7\"></a><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Tekstuele output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Grafische output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Literatuurlijst <br>\n",
    "\n",
    "{1} https://www.fiixsoftware.com/maintenance-strategies/predictive-maintenance/ <br>\n",
    "{2} https://www.fiixsoftware.com/maintenance-strategies/reactive-maintenance/ <br>\n",
    "{3} https://www.fiixsoftware.com/maintenance-strategies/preventative-maintenance/ <br>"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "01ab45f3ee86d7021ac4a7b632c3bd0a262d7b9f8d2eee48d079bad2876dad4c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
