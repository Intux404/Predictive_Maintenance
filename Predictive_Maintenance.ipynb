{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Maintenance\n",
    "\n",
    "## Inleiding\n",
    "\n",
    "**Auteurs:** R. Coenen, Y. Dera, M. Vliex & S. van Wesel <br>\n",
    "**TODO** Inleiding verder afschrijven\n",
    "\n",
    "## Inhoudsopgave\n",
    "\n",
    "* [1. Data selectie](#DataSelectie)\n",
    "* [1.1. Achtergrond informatie](#AchtergrondInfo)\n",
    "* [1.2. Theoretisch kader](#TheoretischKader)\n",
    "* [1.3. Doel](#Doel)\n",
    "* [2. Data preparatie](#DataPreparatie)\n",
    "* [2.1. Data profiling](#DataProfiling)\n",
    "* [2.2. Data Cleaning](#DataCleaning)\n",
    "* [2.3. Data Wrangling](#DataWrangling)\n",
    "* [3. Uitwerkingen en algoritmen](#Uitwerkingen)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data selectie <a class=\"anchor\" id=\"DataSelectie\"></a><br>\n",
    "Vanuit de opdrachtgever is vraag gekomen aan de slag te gaan met machine learning op het gebied van predictive maintenance. Hierbij heeft de opdrachtgever de projectgroep in staat gesteld op zoek te gaan naar een dataset die betrekking heeft op het voorspellen van onderhoud van machines. De aard van deze machines is vrij om te kiezen, ook zal de projectgroep zich gaan verdiepen in specifieke machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Achtergrond informatie <a class=\"anchor\" id=\"AchtergrondInfo\"></a>\n",
    "De dataset die gehanteerd wordt voor het onderzoek is gevonden via [Kaggle](https://www.kaggle.com/) met de naam \"Microsoft Azure Predictive Maintenance\". De dataset is te raadplegen via de [*Website van Kaggle*](https://www.kaggle.com/arnabbiswas1/microsoft-azure-predictive-maintenance) {1}. De dataset is een verzameling van een totaal van 5 bestanden met een totaal van 18 kolommen die overlap met elkaar kennen. Hiermee wordt bedoelt dat in sommige kollomen dezelfde kolomnamen terugkomen (een voorbeeld hiervan is het machineID). Hiernaast is de bron oorspronkelijk afkomstig van [Azure AI Notebooks for predictive Maintenance](https://docs.microsoft.com/nl-nl/azure/architecture/data-science-process/predictive-maintenance-playbook#training-resources-for-predictive-maintenance) {2}, maar aangezien de downloadlink niet meer op de site van Azure te vinden is, is deze beschikbaar gesteld op Kaggle. Op basis van de 18 kolommen is het mogelijk onderhoud van machines te voorspellen, wat deze kolommen betekenen is terug te vinden in [paragraaf 2.1.2.](#TyperenData). \n",
    "\n",
    "Aan de projectgroep is de opdracht verstrekt om op zoek te gaan naar een dataset die betrekking heeft op de monitoring van apparatuur/machines in combinatie met sensoren. Op basis van deze sensor informatie zou o.a. een predictie gemaakt kunnen worden over de resterende levensduur van een apparaat en/of component evenals wanneer onderhoud wenselijk is. \n",
    "\n",
    "De doelstelling is, om op basis van een (preprocessed) dataset een onderzoek uit te voeren en een pipeline te realiseren die aan de slag gaat met deze (ruwe) data en dit omzet naar een predictie model. Dit binnen een Jupyter Notebook en in combinatie met Python scripts.\n",
    "\n",
    "In een introductie gesprek zijn de volgende 3 typeringen van onderhoud aan bod gekomen:\n",
    "\n",
    "<b>Reactive (reactief)</b> - Onderhoud uitvoeren zodra er een probleem is<br>\n",
    "Probleem: onverwachte storingen kunnen duur (kosten) en potentieel gevaarlijk zijn\n",
    "\n",
    "<b>Scheuduled (gepland)</b> - Onderhoud uitvoeren op basis van een (regelmatig) schema<br>\n",
    "Probleem: onnodig onderhoud kan verspilling zijn; mogelijk worden niet alle storingen verholpen\n",
    "\n",
    "<b>Predictive (voorspellend)</b> - Voorspellen wanneer zich problemen zullen voordoen<br>\n",
    "Probleem: moeilijk om nauwkeurige voorspellingen te doen voor complexe apparatuur\n",
    "\n",
    "Kortweg gezegd is het doel om kosten te verminden door te voorspellen wanneer onderhoud nodig is. \n",
    "\n",
    "De projectgroep is aan de slag gegaan met het zoeken naar datasets en eenieder heeft verschillende datasets ingebracht om mee aan te slag te gaan. Vervolgens is de keuze gemaakt voor één dataset, de Microsoft Azure Predictive Maintenance dataset, zoals beschikbaar gesteld op <a href=\"https://www.kaggle.com/arnabbiswas1/microsoft-azure-predictive-maintenance\" title=\"Azure dataset\">Kaggle</a>. \n",
    "\n",
    "Deze (voorbeeld) data is afkomstig van het Microsoft project \"Azure AI Notebooks for Predictive Maintenance\" (welke per 15 oktober 2020 beëndigd is). De data is echter nog altijd toegankelijk om te gebruiken.\n",
    "\n",
    "Deze dataset kan volgens Microsoft gebruikt worden om aan te slag te gaan met machine learning models gerelateerd aan predictive maintenance, ofwel het voorspellen van onderhoud.\n",
    "\n",
    "De dataset bestaat uit een vijftal CSV (door komma gescheiden) bestanden, namelijk errors, fouten, machines, onderhoud en telemetrie en beslaat bijna een miljoen rijen.\n",
    "\n",
    "Iets dieper uitgediept zien de datasets er als volgt uit:\n",
    "\n",
    "• <b>Machinecondities en -gebruik</b>: Geeft de omstandigheden van de machine in gebruik weer, bijvoorbeeld door sensoren verzamelde gegevens;<br>\n",
    "• <b>Faal geschiedenis</b>: De storingshistorie van een machine of een component binnen de machine;<br>\n",
    "• <b>Onderhoudshistorie</b>: De reparatiegeschiedenis van een machine, bijvoorbeeld foutcodes, eerdere onderhoudsactiviteiten of vervanging van componenten.<br>\n",
    "• <b>Machine eigenschapen</b>: De kenmerken van een machine, bijv. CPU, merk en model, locatie.\n",
    "\n",
    "Op detailniveau bestaan de CSV bestanden uit de volgende gegevens:<br><br>\n",
    "• <b>Telemetrie tijd data</b>: Bevat data, op uur niveau, over de rotatie, druk en trillingen; verzameld over 10 machines (in het jaar 2015);<br>\n",
    "• <b>Error</b>: Dit zijn fouten die de machines ondervinden wanneer ze in werking/actief zijn. Aangezien deze fouten de machines niet uitschakelen, worden zij niet als verstoringen beschouwd. (De foutdatum en -tijd worden afgerond op het dichtstbijzijnde uur, aangezien de telemetriegegevens om het uur worden verzameld);<br>\n",
    "• <b>Onderhoud</b>: Wanneer een onderdeel van een machine wordt vervangen, wordt dat als een record in deze tabel vastgelegd. Componenten worden in twee situaties vervangen:<br><br> \n",
    "-> 1. Tijdens het reguliere geplande bezoek vervangt de technicus het onderdeel (proactief onderhoud);<br><br>\n",
    "-> 2. Een onderdeel gaat kapot en de technicus voert een ongepland onderhoud uit om het onderdeel te vervangen (reactief onderhoud). (Dit wordt beschouwd als een storing en de overeenkomstige gegevens worden vastgelegd onder verstoringen. De onderhoudsgegevens hebben zowel betrekking op 2014 als op 2015. Deze gegevens worden afgerond op het dichtstbijzijnde uur, aangezien de telemetriegegevens om het uur worden verzameld).<br><br>\n",
    "• <b>Verstoringen</b>: Elk record staat voor de vervanging van een onderdeel als gevolg van een defect. Deze gegevens zijn een deelverzameling van de onderhoudsgegevens. (Deze gegevens worden afgerond op het dichtstbijzijnde uur, aangezien de telemetriegegevens om het uur worden verzameld)<br>\n",
    "• <b>Metadata</b>: Model type en leeftijd van de machines\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Theoretisch kader <a class=\"anchor\" id=\"TheoretischKader\"></a><br>\n",
    "\n",
    "> Inhoud\n",
    "> + [Introductie](#TKIntroductie)\n",
    "> + [Predictive Maintenance](#TKPredictiveMaint)\n",
    "\n",
    "### Introductie <a class=\"anchor\" id=\"TKIntroductie\"></a>\n",
    "\n",
    "### 1.2.1. Predictive maintenance <a class=\"anchor\" id=\"TKPredictiveMaint\"></a>\n",
    "Predictive maintenance is een techniek dat gebruik maakt van data analyse tools en technieken om afwijkingen in een organisatie en mogelijke gebreken in apparatuur en processen vroegtijdig te detecteren zodat deze afgehandeld kunnen worden nog vóór dat deze resulteren in een fout. [FiixSoftware.com](https://www.fiixsoftware.com/maintenance-strategies/predictive-maintenance/) {3}. Enerzijds focust predictive maintenance zich op het voorkomen van [reactive maintenance]([#TKReactiveMaint](https://www.fiixsoftware.com/maintenance-strategies/reactive-maintenance/)), waarbij het anderzijds de kosten voor [preventive maintenance]([#TKPreventiveMaint](https://www.fiixsoftware.com/maintenance-strategies/preventative-maintenance/)) probeert te verlagen.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Doel <a class=\"anchor\" id=\"Doel\"></a><br>\n",
    "Het doel van het project betreft het inzichtelijk maken van de mogelijkheden van het gebruik van machine learning binnen predictive maintenance richting de opdrachtgever. Hierbij zal de projectgroep zich verdiepen in een open dataset (waarover de opdrachtgever geen kennis noch eigendom heeft), gericht op predictive maintenance. Dit betekent dat vanuit het perspectief van data gezocht wordt naar inzichten en er geen specifiek probleem aanwezig is. Hiermee wordt het project gekenmerkt met een data driven benadering.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data preparatie <a class=\"anchor\" id=\"DataPreparatie\"></a><br>\n",
    "Voordat er aan de slag gegaan kan worden met de data(set) dienen er een aantal stappen/iteraties over de data uitgevoerd te worden, te weten: verzamelen (1), typeren(2), opschonen (3) en voorbewerken (4).\n",
    "\n",
    "Het volgende hoofdstuk behandeld deze viertal fases en beschrijft de activiteiten die plaats hebben gevonden binnen deze fases.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Data profiling <a class=\"anchor\" id=\"DataProfiling\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1. Inladen van de data <a class=\"anchor\" id=\"InladenData\"></a><br>\n",
    "Om aan de slag te kunnen gaan met de data, dient deze eerst ingeladen te worden. Deze dataset, afkomstig van Kaggle, bevat een cijftal .CSV (kommagescheiden) bestanden, die in zijn totaliteit uit 18 kolommen en 876.100 rijen bestaat. Het inladen van de data kan gebeuren aan de hand van de Pandas module binnen Python. Hiervoor wordt de regel code ```import pandas as pd``` uitgevoerd. Hiermee wordt de Pandas module geïmporteerd en hernoemd naar 'pd' zodat de module met deze afkorting aangeroepen kan worden i.p.v. het voluit schrijven van de modulenaam. Wanneer Pandas is geïmporteerd kunnen de bronbestanden ingeladen worden in allen een aparte dataframe. Dit gebeurd middels de volgende regels code: \n",
    "\n",
    "```\n",
    "dfTelemetry = pd.read_csv ('Data\\PdM_telemetry.csv')\n",
    "dfErrors = pd.read_csv ('Data\\PdM_errors.csv')\n",
    "dfFailures = pd.read_csv ('Data\\PdM_failures.csv')\n",
    "dfMachines = pd.read_csv ('Data\\PdM_machines.csv')\n",
    "dfMaint = pd.read_csv ('Data\\PdM_maint.csv')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTelemetry = pd.read_csv ('Data\\PdM_telemetry.csv')\n",
    "dfErrors = pd.read_csv ('Data\\PdM_errors.csv')\n",
    "dfFailures = pd.read_csv ('Data\\PdM_failures.csv')\n",
    "dfMachines = pd.read_csv ('Data\\PdM_machines.csv')\n",
    "dfMaint = pd.read_csv ('Data\\PdM_maint.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deze regels code zorgen ervoor dat de juiste CSV (kommagescheiden bestanden) ingeladen worden. Deze code zorgt er voor dat er een \"data frame object\" terug gegeven wordt; dit kan gezien worden als een soort van Excel bestand. De df(naam) code (bijv. 'dfTelemetry') zorgt ervoor dat deze dataframes snel opgeroepen kunnen worden. Met onderstaande code kan er een voorbeeld van het data frame getoond worden inclusief een vertoning van de rijen en kolommen. In dit geval wordt het dataframe Telemetry (meetgegevens) inzichtelijk gemaakt middels de regel code ```dfTelemetry```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTelemetry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2. Typeren van de data <a class=\"anchor\" id=\"TyperenData\"></a>\n",
    "\n",
    "**Format** <br>\n",
    "Deze dataset bevat gestructureerde gegevens. Iedere atribuut valt onder een categorie. De dataset zelf bevat, op moment van verkrijgen, nog uit een vijftal losse CSV bestanden. Deze staan los van elkaar en dienen nog, middels relaties, gekoppeld te worden eaan elkaar. Zie voor meer informatie hoofdstuk 2.3 'Data Wrangling'.\n",
    "\n",
    "**Structuur** <br>\n",
    "Het data format betreft dus een CSV bestand. Een CSV-bestand (door komma’s gescheiden waarden) is een bestandstype, In CSV-bestanden wordt informatie niet in kolommen opgeslagen, maar wordt deze gescheiden door komma’s.\n",
    "\n",
    "**Context**<br>\n",
    "De volgende kolommen zijn terug te vinden in de datasets:\n",
    "\n",
    "| Feature   | Omschrijving | Voorbeeld data    | Data Type | Type variabele | Meeteenheid | (Oorspronkelijke) databron |\n",
    "| ----------| -------------| ----------------- | ----------| ---------------| ------------|  --------------------------|\n",
    "| machineID | Iedere machine wordt gekenmerkt door een uniek identificatienummer | 1 | Int64 | Kwalitatief (discreet) | n.v.t | PdM_machines.csv |\n",
    "| model     | Er zijn verschillende soorten modellen, die gekenmerkt worden door een modelnummer | model 3 | text | Kwalitatief (discreet) | n.v.t |PdM_machines.csv |\n",
    "| age       | De leeftijd van de machines/compontenten | 18 | Int64 | Kwantitatief (discreet) | Maanden | PdM_machines.csv |\n",
    "| datetime  | Geeft de datum en tijd weer | 3-1-2015 07:00:00 | datetime | Kwantitatief (continue) | Uren, minuten, seconde | PdM_errors.csv     |\n",
    "| errorID   | Iedere error wordt gekenmerkt door een (uniek) error nummer | error1 | text | Kwalitatief (discreet) | n.v.t | PdM_errors.csv     |\n",
    "| failure   | Geeft aan welk component gefaald is | comp4 | text | Kwalitatief (discreet) | n.v.t | PdM_failures.csv |\n",
    "| comp      | Ieder component wordt gekenmerkt door een componentnummer | comp2 | text | Kwalitatief (discreet) | n.v.t | PdM_maint.csv |\n",
    "| volt      | De elektrische spanning in volt | 176217853015625 | Int64 | Kwantitatief (continue)| n.v.t | PdM_maint.csv |\n",
    "| rotate    | < Nog invullen > | 418504078221616   | Int64 | Kwantitatief (continue) | n.v.t | PdM_maint.csv  |\n",
    "| pressure  | < Nog invullen > | 113077935462083   | Int64 | Kwantitatief (continue) | n.v.t | PdM_maint.csv  |\n",
    "| vibration | Periodieke beweging van een voorwerp of medium | 450876857639276 | Int64 | Kwantitatief (continue) | n.v.t | PdM_maint.csv |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Data Wrangling <a class=\"anchor\" id=\"DataWrangling\"></a>\n",
    "Data wrangling betreft het op elkaar laten passen van de data. Tot nu toe betreffen het 5 losse datasets die allen op elkaar dienen te passen. Dat zal in deze paragraaf aan bod komen.  \n",
    "\n",
    "De eerste stap van het op elkaar laten passen is het inzichtelijk maken van het datamodel. Middels gebruik te maken van [Microsoft PowerBI](https://powerbi.microsoft.com/nl-nl/) wordt een model opgesteld waarbij de relaties tussen de tabellen geïdentificeerd kunnen worden. Dit heeft als resultaat het onderstaat Entity Attribute Relation Diagram (EARD):\n",
    "\n",
    "<img src=\"img/Oorspronkelijk_dataModel.png\" alt=\"oorspronkelijk datamodel\" width=\"650\"/><br>\n",
    "*Oorspronkelijk datamodel*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>machineID</th>\n",
       "      <th>Error1</th>\n",
       "      <th>Error2</th>\n",
       "      <th>Error3</th>\n",
       "      <th>Error4</th>\n",
       "      <th>Error5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-03 07:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-03 20:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-04 06:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-10 15:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-22 10:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3914</th>\n",
       "      <td>2015-11-21 08:00:00</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3915</th>\n",
       "      <td>2015-12-04 02:00:00</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3916</th>\n",
       "      <td>2015-12-08 06:00:00</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3917</th>\n",
       "      <td>2015-12-08 06:00:00</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3918</th>\n",
       "      <td>2015-12-22 03:00:00</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3919 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 datetime  machineID Error1 Error2 Error3 Error4 Error5\n",
       "0     2015-01-03 07:00:00          1      1    NaN    NaN    NaN    NaN\n",
       "1     2015-01-03 20:00:00          1    NaN    NaN      1    NaN    NaN\n",
       "2     2015-01-04 06:00:00          1    NaN    NaN    NaN    NaN      1\n",
       "3     2015-01-10 15:00:00          1    NaN    NaN    NaN      1    NaN\n",
       "4     2015-01-22 10:00:00          1    NaN    NaN    NaN      1    NaN\n",
       "...                   ...        ...    ...    ...    ...    ...    ...\n",
       "3914  2015-11-21 08:00:00        100    NaN      1    NaN    NaN    NaN\n",
       "3915  2015-12-04 02:00:00        100      1    NaN    NaN    NaN    NaN\n",
       "3916  2015-12-08 06:00:00        100    NaN      1    NaN    NaN    NaN\n",
       "3917  2015-12-08 06:00:00        100    NaN    NaN      1    NaN    NaN\n",
       "3918  2015-12-22 03:00:00        100    NaN    NaN      1    NaN    NaN\n",
       "\n",
       "[3919 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pandas lib for dataframe operations\n",
    "import pandas as pd\n",
    "#numpy lib for two-dimensional arrays\n",
    "import numpy as np\n",
    "#scikit learn lib for visualising data\n",
    "import sklearn as sk\n",
    "#matplot lib for visualising data\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "#seaborn lib for visualising more fancy which is based on the matplot lib\n",
    "import seaborn as sb\n",
    "import math as math\n",
    "\n",
    "# Loading all data files\n",
    "dfTelemetry = pd.read_csv ('data\\PdM_telemetry.csv')\n",
    "dfErrors = pd.read_csv ('data\\PdM_errors.csv')\n",
    "dfFailures = pd.read_csv ('data\\PdM_failures.csv')\n",
    "dfMachines = pd.read_csv ('data\\PdM_machines.csv')\n",
    "dfMaint = pd.read_csv ('data\\PdM_maint.csv')\n",
    "\n",
    "#Merging the tables into the dataframe\n",
    "\n",
    "# #Left join failures on maintenance to create df1\n",
    "df1 = pd.merge(dfMaint, dfFailures, how='left', left_on=['datetime', 'machineID', 'comp'], right_on = ['datetime', 'machineID', 'failure'])\n",
    "df1['failure'] = df1['failure'].fillna(0) #indicates maint was not a failure\n",
    "df1.loc[((df1.failure == 'comp1') | (df1.failure == 'comp2') | (df1.failure == 'comp3') | (df1.failure == 'comp4')), 'failure'] = '1' #indicates maintenance was a failure\n",
    "# df1.to_csv('data/df1output.csv') #test output to validate\n",
    "\n",
    "# #Clean error table to create df2, df2 = cleansed dfErrors tbl. \n",
    "df2 = dfErrors\n",
    "df2['Error1'] = np.nan\n",
    "df2['Error2'] = np.nan\n",
    "df2['Error3'] = np.nan\n",
    "df2['Error4'] = np.nan\n",
    "df2['Error5'] = np.nan\n",
    "\n",
    "df2.loc[(df2['errorID'] == 'error1'), 'Error1'] = '1'\n",
    "df2.loc[(df2['errorID'] == 'error2'), 'Error2'] = '1'\n",
    "df2.loc[(df2['errorID'] == 'error3'), 'Error3'] = '1'\n",
    "df2.loc[(df2['errorID'] == 'error4'), 'Error4'] = '1'\n",
    "df2.loc[(df2['errorID'] == 'error5'), 'Error5'] = '1'\n",
    "\n",
    "df2.drop('errorID', axis=1, inplace=True)\n",
    "\n",
    "# df2.drop(columns=['errorID'])\n",
    "\n",
    "# df2.to_csv('data/df2output.csv') #test output to validate\n",
    "\n",
    "df2\n",
    "\n",
    "\n",
    "\n",
    "# dfErrorCheck = (dfErrors.groupby(['errorID', 'machineID', 'datetime']).size().groupby(level=2).max()\n",
    "#     .sort_values(ascending=True)\n",
    "#     .reset_index(name='errorCount')\n",
    "#     # .drop_duplicates(subset='errorID')\n",
    "# )\n",
    "\n",
    "# dfErrorCheck\n",
    "\n",
    "\n",
    "# dfErrorCount = dfErrors\n",
    "# dfErrorCount= dfErrors.groupby(['machineID', 'datetime'], sort=False).size().reset_index(name = 'errorCount')\n",
    "# dfErrorCount.loc[(dfErrorCount.errorCount > 1) & (dfErrors.errorID == 'error1'), 'error1'] = 1\n",
    "# dfErrorCount.loc[(dfErrorCount.errorCount > 1) & (dfErrors.errorID == 'error2'), 'error2'] = 1\n",
    "# dfErrorCount.loc[(dfErrorCount.errorCount > 1) & (dfErrors.errorID == 'error3'), 'error3'] = 1\n",
    "# dfErrorCount.loc[(dfErrorCount.errorCount > 1) & (dfErrors.errorID == 'error4'), 'error4'] = 1\n",
    "# dfErrorCount.loc[(dfErrorCount.errorCount > 1) & (dfErrors.errorID == 'error5'), 'error5'] = 1\n",
    "# dfErrorCount.to_csv('data/dfECoutput.csv') #test output to validate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Right join machines on df1 to create df2\n",
    "# df2 = pd.merge(dfMachines, df1, how='right', left_on=['machineID'], right_on=['machineID'])\n",
    "# df2\n",
    "\n",
    "# #Merge errors on df2 (machines, maint & failures)\n",
    "# df3 = pd.merge(dfErrors, df2, how='right')\n",
    "# df3\n",
    "\n",
    "#Concatenation of datasets\n",
    "# https://www.youtube.com/watch?v=iYWKfUOtGaw&ab_channel=DataSchool\n",
    "# df = pd.concat((dfTelemetry, dfMachines, dfErrors, dfFailures, dfMaint))\n",
    "# print (df.head(1000))\n",
    "# print (dfTelemetry.head(1000))\n",
    "# print (dfTelemetry.machineID.nunique())\n",
    "# print (dfErrors.machineID.nunique())\n",
    "# print (dfFailures.machineID.nunique())\n",
    "# print (dfMachines.machineID.nunique())\n",
    "# print (dfMaint.machineID.nunique())\n",
    "# print (df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Data cleaning <a class=\"anchor\" id=\"DataCleaning\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Uitwerkingen en algoritmen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['datetime', 'machineID', 'volt', 'rotate', 'pressure', 'vibration'], dtype='object')\n",
      "Index(['datetime', 'machineID', 'errorID'], dtype='object')\n",
      "Index(['datetime', 'machineID', 'failure'], dtype='object')\n",
      "Index(['machineID', 'model', 'age'], dtype='object')\n",
      "Index(['datetime', 'machineID', 'comp'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "dfTelemetry = pd.read_csv ('data\\PdM_telemetry.csv')\n",
    "dfErrors = pd.read_csv ('data\\PdM_errors.csv')\n",
    "dfFailures = pd.read_csv ('data\\PdM_failures.csv')\n",
    "dfMachines = pd.read_csv ('data\\PdM_machines.csv')\n",
    "dfMaint = pd.read_csv ('data\\PdM_maint.csv')\n",
    "print (dfTelemetry.columns)\n",
    "print (dfErrors.columns)\n",
    "print (dfFailures.columns)\n",
    "print (dfMachines.columns)\n",
    "print (dfMaint.columns)\n",
    "\n",
    "# print (dfTelemetry.dtypes)\n",
    "# dfErrors.errorID.to_string()\n",
    "# print (dfErrors.errorID.dtypes)\n",
    "# print (dfFailures.dtypes)\n",
    "# print (dfMachines.dtypes)\n",
    "# print (dfMaint.dtypes)\n",
    "\n",
    "# df = pd.concat((dfTelemetry, dfErrors, dfFailures, dfMachines, dfMaint))\n",
    "# df.head(800)\n",
    "# df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliografie\n",
    "+ [Microsoft Predictive Maintenance](https://www.kaggle.com/arnabbiswas1/microsoft-azure-predictive-maintenance) {1}\n",
    "+ [What is predictive maintenance?](https://www.fiixsoftware.com/maintenance-strategies/predictive-maintenance/) {2}"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "df91481e84a2b848202e6e50f0fbb9aa107aded72c389e66e2482a76ade2318d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
